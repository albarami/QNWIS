<?xml version="1.0" encoding="utf-8"?><testsuites name="pytest tests"><testsuite name="pytest" errors="31" failures="43" skipped="1" tests="214" time="144.176" timestamp="2025-11-08T16:15:22.813001+00:00" hostname="VM-MOL-ITLY-A10"><testcase classname="tests.integration.agents.test_pattern_miner_integration.TestStableRelationsIntegration" name="test_end_to_end_with_strong_correlation" time="0.003" /><testcase classname="tests.integration.agents.test_pattern_miner_integration.TestStableRelationsIntegration" name="test_narrative_includes_all_metadata" time="0.001" /><testcase classname="tests.integration.agents.test_pattern_miner_integration.TestStableRelationsIntegration" name="test_multiple_drivers_ranked" time="0.002" /><testcase classname="tests.integration.agents.test_pattern_miner_integration.TestSeasonalEffectsIntegration" name="test_end_to_end_seasonal_analysis" time="0.001" /><testcase classname="tests.integration.agents.test_pattern_miner_integration.TestSeasonalEffectsIntegration" name="test_narrative_structure_complete" time="0.001" /><testcase classname="tests.integration.agents.test_pattern_miner_integration.TestDriverScreenIntegration" name="test_end_to_end_cohort_screening" time="0.005" /><testcase classname="tests.integration.agents.test_pattern_miner_integration.TestDriverScreenIntegration" name="test_multiple_cohorts_mentioned" time="0.003" /><testcase classname="tests.integration.agents.test_pattern_miner_integration.TestDriverScreenIntegration" name="test_multiple_windows_processed" time="0.003" /><testcase classname="tests.integration.agents.test_pattern_miner_integration.TestDerivedResultProvenance" name="test_stable_relations_derived_qid_format" time="0.001" /><testcase classname="tests.integration.agents.test_pattern_miner_integration.TestDerivedResultProvenance" name="test_seasonal_effects_derived_qid_format" time="0.002" /><testcase classname="tests.integration.agents.test_pattern_miner_integration.TestDerivedResultProvenance" name="test_driver_screen_derived_qid_format" time="0.001" /><testcase classname="tests.integration.agents.test_pattern_miner_integration.TestCitationCompliance" name="test_stable_relations_includes_citations" time="0.001" /><testcase classname="tests.integration.agents.test_pattern_miner_integration.TestCitationCompliance" name="test_seasonal_effects_includes_citations" time="0.001" /><testcase classname="tests.integration.agents.test_pattern_miner_integration.TestCitationCompliance" name="test_freshness_included" time="0.001" /><testcase classname="tests.integration.agents.test_predictor_agent.TestPredictorForecastBaseline" name="test_successful_forecast" time="0.013" /><testcase classname="tests.integration.agents.test_predictor_agent.TestPredictorForecastBaseline" name="test_insufficient_data_error" time="0.003" /><testcase classname="tests.integration.agents.test_predictor_agent.TestPredictorForecastBaseline" name="test_horizon_validation" time="0.003" /><testcase classname="tests.integration.agents.test_predictor_agent.TestPredictorForecastBaseline" name="test_query_not_found_error" time="0.003" /><testcase classname="tests.integration.agents.test_predictor_agent.TestPredictorEarlyWarning" name="test_successful_warning_no_flags" time="0.008" /><testcase classname="tests.integration.agents.test_predictor_agent.TestPredictorEarlyWarning" name="test_successful_warning_with_spike" time="0.008" /><testcase classname="tests.integration.agents.test_predictor_agent.TestPredictorEarlyWarning" name="test_insufficient_data_error" time="0.002" /><testcase classname="tests.integration.agents.test_predictor_agent.TestPredictorScenarioCompare" name="test_successful_comparison" time="0.008" /><testcase classname="tests.integration.agents.test_predictor_agent.TestPredictorScenarioCompare" name="test_single_method_comparison" time="0.003" /><testcase classname="tests.integration.agents.test_predictor_agent.TestPredictorScenarioCompare" name="test_insufficient_data_error" time="0.002" /><testcase classname="tests.integration.agents.test_predictor_agent.TestPredictorIntegration" name="test_forecast_produces_valid_qids" time="0.013" /><testcase classname="tests.integration.agents.test_predictor_agent.TestPredictorIntegration" name="test_early_warning_produces_valid_qids" time="0.008" /><testcase classname="tests.integration.agents.test_predictor_agent.TestPredictorIntegration" name="test_reproducibility_snippets_present" time="0.023" /><testcase classname="tests.integration.agents.test_step13_end_to_end.TestStep13EndToEnd" name="test_pattern_detective_only_uses_dataclient_methods" time="1.739" /><testcase classname="tests.integration.agents.test_step13_end_to_end.TestStep13EndToEnd" name="test_national_strategy_only_uses_dataclient_methods" time="1.733" /><testcase classname="tests.integration.agents.test_step13_end_to_end.TestStep13EndToEnd" name="test_pattern_detective_narrative_structure" time="1.718" /><testcase classname="tests.integration.agents.test_step13_end_to_end.TestStep13EndToEnd" name="test_national_strategy_narrative_structure" time="1.705"><skipped type="pytest.skip" message="Insufficient GCC data in synthetic dataset">d:\lmis_int\tests\integration\agents\test_step13_end_to_end.py:139: Insufficient GCC data in synthetic dataset</skipped></testcase><testcase classname="tests.integration.agents.test_step13_end_to_end.TestStep13EndToEnd" name="test_pattern_detective_best_practices_full_narrative" time="1.687" /><testcase classname="tests.integration.agents.test_step13_end_to_end.TestStep13EndToEnd" name="test_national_strategy_vision2030_full_narrative" time="1.703" /><testcase classname="tests.integration.agents.test_step13_end_to_end.TestStep13EndToEnd" name="test_agent_reports_contain_warnings_when_applicable" time="1.723" /><testcase classname="tests.integration.agents.test_step13_end_to_end.TestStep13EndToEnd" name="test_no_direct_execute_query_calls" time="1.726" /><testcase classname="tests.integration.agents.test_step13_end_to_end.TestStep13EndToEnd" name="test_all_evidence_includes_query_ids" time="1.682" /><testcase classname="tests.integration.agents.test_step13_end_to_end.TestStep13EndToEnd" name="test_derived_results_have_proper_query_ids" time="1.693" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_basic_invocation" time="1.480" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_json_output_structure" time="1.443" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_markdown_output" time="1.448" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_parameter_passing" time="1.443" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_request_id_tracking" time="1.434" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_missing_required_intent" time="1.375" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_invalid_intent" time="1.385" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_disabled_intent" time="1.420" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_help_flag" time="1.396" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_log_level" time="1.425" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_multiple_metrics" time="1.434" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_year_range_parameters" time="1.434" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_numeric_parameters" time="1.434" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_output_directory_creation" time="1.416" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_stdout_output" time="1.455" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_user_id_tracking" time="1.433" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_missing_config_file" time="1.406" /><testcase classname="tests.integration.orchestration.test_cli" name="test_cli_json_format_default" time="1.406" /><testcase classname="tests.integration.orchestration.test_cli_query_mode" name="test_cli_query_mode_anomalies" time="1.477"><failure message="AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour&#10;  2025-11-08 16:16:11,759 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Find anomalies in Healthcare retention last 24 months&quot;?&#10;  &#10;assert 1 == 0">@pytest.mark.integration
    def test_cli_query_mode_anomalies() -&gt; None:
        """Test CLI with query for anomaly detection."""
        query = "Find anomalies in Healthcare retention last 24 months"
    
        exit_code, stdout, stderr = run_cli_query(query)
    
        # Should exit successfully
&gt;       assert exit_code == 0, f"CLI failed with stderr: {stderr}"
E       AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour
E         2025-11-08 16:16:11,759 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Find anomalies in Healthcare retention last 24 months"?
E         
E       assert 1 == 0

tests\integration\orchestration\test_cli_query_mode.py:63: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_cli_query_mode" name="test_cli_query_mode_correlation" time="1.465"><failure message="AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour&#10;  2025-11-08 16:16:13,466 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Is there a correlation between salary and retention in Construction?&quot;?&#10;  &#10;assert 1 == 0">@pytest.mark.integration
    def test_cli_query_mode_correlation() -&gt; None:
        """Test CLI with query for correlation analysis."""
        query = "Is there a correlation between salary and retention in Construction?"
    
        exit_code, stdout, stderr = run_cli_query(query)
    
        # Should exit successfully
&gt;       assert exit_code == 0, f"CLI failed with stderr: {stderr}"
E       AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour
E         2025-11-08 16:16:13,466 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Is there a correlation between salary and retention in Construction?"?
E         
E       assert 1 == 0

tests\integration\orchestration\test_cli_query_mode.py:99: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_cli_query_mode" name="test_cli_query_mode_gcc_benchmark" time="1.464"><failure message="AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour&#10;  2025-11-08 16:16:14,934 - src.qnwis.orchestration.nodes.invoke - ERROR - Agent invocation failed&#10;  Traceback (most recent call last):&#10;    File &quot;d:\lmis_int\src\qnwis\agents\base.py&quot;, line 180, in run&#10;      res = execute_cached(query_id, self._registry, ttl_s=self.ttl_s)&#10;            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^&#10;    File &quot;d:\lmis_int\src\qnwis\data\deterministic\cache_access.py&quot;, line 195, in execute_cached&#10;      source_spec = spec_override or registry.get(query_id)&#10;                                     ^^^^^^^^^^^^^^^^^^^^^^&#10;    File &quot;d:\lmis_int\src\qnwis\data\deterministic\registry.py&quot;, line 99, in get&#10;      return self._items[qid]&#10;             ~~~~~~~~~~~^^^^^&#10;  KeyError: 'syn_unemployment_rate_gcc_latest'&#10;  &#10;  The above exception was the direct cause of the following exception:&#10;  &#10;  Traceback (most recent call last):&#10;    File &quot;d:\lmis_int\src\qnwis\orchestration\nodes\invoke.py&quot;, line 196, in invoke_agent&#10;      result = method(**valid_params)&#10;               ^^^^^^^^^^^^^^^^^^^^^^&#10;    File &quot;d:\lmis_int\src\qnwis\agents\national_strategy.py&quot;, line 88, in gcc_benchmark&#10;      gcc_res = self.client.run(&quot;syn_unemployment_rate_gcc_latest&quot;)&#10;                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^&#10;    File &quot;d:\lmis_int\src\qnwis\agents\base.py&quot;, line 189, in run&#10;      self._raise_missing(query_id, cause=exc)&#10;    File &quot;d:\lmis_int\src\qnwis\agents\base.py&quot;, line 163, in _raise_missing&#10;      raise MissingQueryDefinitionError(&#10;  src.qnwis.agents.base.MissingQueryDefinitionError: Deterministic query 'syn_unemployment_rate_gcc_latest' is not registered in 'data\queries'. No YAML definition was loaded for 'syn_unemployment_rate_gcc_latest'.&#10;  2025-11-08 16:16:14,937 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Agent error: MissingQueryDefinitionError: Deterministic query 'syn_unemployment_rate_gcc_latest' is not registered in 'data\queries'. No YAML definition was loaded for 'syn_unemployment_rate_gcc_latest'.&#10;  &#10;assert 1 == 0">@pytest.mark.integration
    def test_cli_query_mode_gcc_benchmark() -&gt; None:
        """Test CLI with query for GCC benchmark."""
        query = "Compare Qatar wage growth to UAE and Saudi Arabia"
    
        exit_code, stdout, stderr = run_cli_query(query)
    
        # Should exit successfully
&gt;       assert exit_code == 0, f"CLI failed with stderr: {stderr}"
E       AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour
E         2025-11-08 16:16:14,934 - src.qnwis.orchestration.nodes.invoke - ERROR - Agent invocation failed
E         Traceback (most recent call last):
E           File "d:\lmis_int\src\qnwis\agents\base.py", line 180, in run
E             res = execute_cached(query_id, self._registry, ttl_s=self.ttl_s)
E                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           File "d:\lmis_int\src\qnwis\data\deterministic\cache_access.py", line 195, in execute_cached
E             source_spec = spec_override or registry.get(query_id)
E                                            ^^^^^^^^^^^^^^^^^^^^^^
E           File "d:\lmis_int\src\qnwis\data\deterministic\registry.py", line 99, in get
E             return self._items[qid]
E                    ~~~~~~~~~~~^^^^^
E         KeyError: 'syn_unemployment_rate_gcc_latest'
E         
E         The above exception was the direct cause of the following exception:
E         
E         Traceback (most recent call last):
E           File "d:\lmis_int\src\qnwis\orchestration\nodes\invoke.py", line 196, in invoke_agent
E             result = method(**valid_params)
E                      ^^^^^^^^^^^^^^^^^^^^^^
E           File "d:\lmis_int\src\qnwis\agents\national_strategy.py", line 88, in gcc_benchmark
E             gcc_res = self.client.run("syn_unemployment_rate_gcc_latest")
E                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           File "d:\lmis_int\src\qnwis\agents\base.py", line 189, in run
E             self._raise_missing(query_id, cause=exc)
E           File "d:\lmis_int\src\qnwis\agents\base.py", line 163, in _raise_missing
E             raise MissingQueryDefinitionError(
E         src.qnwis.agents.base.MissingQueryDefinitionError: Deterministic query 'syn_unemployment_rate_gcc_latest' is not registered in 'data\queries'. No YAML definition was loaded for 'syn_unemployment_rate_gcc_latest'.
E         2025-11-08 16:16:14,937 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Agent error: MissingQueryDefinitionError: Deterministic query 'syn_unemployment_rate_gcc_latest' is not registered in 'data\queries'. No YAML definition was loaded for 'syn_unemployment_rate_gcc_latest'.
E         
E       assert 1 == 0

tests\integration\orchestration\test_cli_query_mode.py:119: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_cli_query_mode" name="test_cli_query_mode_vision2030" time="1.444"><failure message="AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour&#10;  2025-11-08 16:16:16,390 - src.qnwis.orchestration.nodes.invoke - ERROR - Agent invocation failed&#10;  Traceback (most recent call last):&#10;    File &quot;d:\lmis_int\src\qnwis\agents\base.py&quot;, line 180, in run&#10;      res = execute_cached(query_id, self._registry, ttl_s=self.ttl_s)&#10;            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^&#10;    File &quot;d:\lmis_int\src\qnwis\data\deterministic\cache_access.py&quot;, line 195, in execute_cached&#10;      source_spec = spec_override or registry.get(query_id)&#10;                                     ^^^^^^^^^^^^^^^^^^^^^^&#10;    File &quot;d:\lmis_int\src\qnwis\data\deterministic\registry.py&quot;, line 99, in get&#10;      return self._items[qid]&#10;             ~~~~~~~~~~~^^^^^&#10;  KeyError: 'syn_qatarization_by_sector_latest'&#10;  &#10;  The above exception was the direct cause of the following exception:&#10;  &#10;  Traceback (most recent call last):&#10;    File &quot;d:\lmis_int\src\qnwis\orchestration\nodes\invoke.py&quot;, line 196, in invoke_agent&#10;      result = method(**valid_params)&#10;               ^^^^^^^^^^^^^^^^^^^^^^&#10;    File &quot;d:\lmis_int\src\qnwis\agents\national_strategy.py&quot;, line 303, in vision2030_alignment&#10;      qat_res = self.client.run(&quot;syn_qatarization_by_sector_latest&quot;)&#10;                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^&#10;    File &quot;d:\lmis_int\src\qnwis\agents\base.py&quot;, line 189, in run&#10;      self._raise_missing(query_id, cause=exc)&#10;    File &quot;d:\lmis_int\src\qnwis\agents\base.py&quot;, line 163, in _raise_missing&#10;      raise MissingQueryDefinitionError(&#10;  src.qnwis.agents.base.MissingQueryDefinitionError: Deterministic query 'syn_qatarization_by_sector_latest' is not registered in 'data\queries'. No YAML definition was loaded for 'syn_qatarization_by_sector_latest'.&#10;  2025-11-08 16:16:16,392 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Agent error: MissingQueryDefinitionError: Deterministic query 'syn_qatarization_by_sector_latest' is not registered in 'data\queries'. No YAML definition was loaded for 'syn_qatarization_by_sector_latest'.&#10;  &#10;assert 1 == 0">@pytest.mark.integration
    def test_cli_query_mode_vision2030() -&gt; None:
        """Test CLI with query for Vision 2030 alignment."""
        query = "Assess qatarization progress toward Vision 2030 targets"
    
        exit_code, stdout, stderr = run_cli_query(query)
    
        # Should exit successfully
&gt;       assert exit_code == 0, f"CLI failed with stderr: {stderr}"
E       AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour
E         2025-11-08 16:16:16,390 - src.qnwis.orchestration.nodes.invoke - ERROR - Agent invocation failed
E         Traceback (most recent call last):
E           File "d:\lmis_int\src\qnwis\agents\base.py", line 180, in run
E             res = execute_cached(query_id, self._registry, ttl_s=self.ttl_s)
E                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           File "d:\lmis_int\src\qnwis\data\deterministic\cache_access.py", line 195, in execute_cached
E             source_spec = spec_override or registry.get(query_id)
E                                            ^^^^^^^^^^^^^^^^^^^^^^
E           File "d:\lmis_int\src\qnwis\data\deterministic\registry.py", line 99, in get
E             return self._items[qid]
E                    ~~~~~~~~~~~^^^^^
E         KeyError: 'syn_qatarization_by_sector_latest'
E         
E         The above exception was the direct cause of the following exception:
E         
E         Traceback (most recent call last):
E           File "d:\lmis_int\src\qnwis\orchestration\nodes\invoke.py", line 196, in invoke_agent
E             result = method(**valid_params)
E                      ^^^^^^^^^^^^^^^^^^^^^^
E           File "d:\lmis_int\src\qnwis\agents\national_strategy.py", line 303, in vision2030_alignment
E             qat_res = self.client.run("syn_qatarization_by_sector_latest")
E                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           File "d:\lmis_int\src\qnwis\agents\base.py", line 189, in run
E             self._raise_missing(query_id, cause=exc)
E           File "d:\lmis_int\src\qnwis\agents\base.py", line 163, in _raise_missing
E             raise MissingQueryDefinitionError(
E         src.qnwis.agents.base.MissingQueryDefinitionError: Deterministic query 'syn_qatarization_by_sector_latest' is not registered in 'data\queries'. No YAML definition was loaded for 'syn_qatarization_by_sector_latest'.
E         2025-11-08 16:16:16,392 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Agent error: MissingQueryDefinitionError: Deterministic query 'syn_qatarization_by_sector_latest' is not registered in 'data\queries'. No YAML definition was loaded for 'syn_qatarization_by_sector_latest'.
E         
E       assert 1 == 0

tests\integration\orchestration\test_cli_query_mode.py:139: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_cli_query_mode" name="test_cli_query_mode_talent_competition" time="1.456"><failure message="AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour&#10;  2025-11-08 16:16:17,863 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Analyze poaching patterns in Finance sector&quot;?&#10;  &#10;assert 1 == 0">@pytest.mark.integration
    def test_cli_query_mode_talent_competition() -&gt; None:
        """Test CLI with query for talent competition."""
        query = "Analyze poaching patterns in Finance sector"
    
        exit_code, stdout, stderr = run_cli_query(query)
    
        # Should exit successfully
&gt;       assert exit_code == 0, f"CLI failed with stderr: {stderr}"
E       AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour
E         2025-11-08 16:16:17,863 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Analyze poaching patterns in Finance sector"?
E         
E       assert 1 == 0

tests\integration\orchestration\test_cli_query_mode.py:159: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_cli_query_mode" name="test_cli_query_mode_low_confidence_fails_gracefully" time="1.446" /><testcase classname="tests.integration.orchestration.test_cli_query_mode" name="test_cli_query_mode_with_output_file" time="1.452"><failure message="AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour&#10;  2025-11-08 16:16:20,770 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Find correlations in Construction retention&quot;?&#10;  &#10;assert 1 == 0">tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_cli_query_mode_with_outpu0')

    @pytest.mark.integration
    def test_cli_query_mode_with_output_file(tmp_path: Path) -&gt; None:
        """Test CLI with --output flag."""
        query = "Find correlations in Construction retention"
        output_file = tmp_path / "result.json"
    
        exit_code, stdout, stderr = run_cli_query(
            query,
            extra_args=["--output", str(output_file)],
        )
    
        # Should exit successfully
&gt;       assert exit_code == 0, f"CLI failed with stderr: {stderr}"
E       AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour
E         2025-11-08 16:16:20,770 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Find correlations in Construction retention"?
E         
E       assert 1 == 0

tests\integration\orchestration\test_cli_query_mode.py:201: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_cli_query_mode" name="test_cli_query_mode_json_includes_metadata" time="1.454"><failure message="AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour&#10;  2025-11-08 16:16:22,238 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Analyze retention trends in Healthcare&quot;?&#10;  &#10;assert 1 == 0">@pytest.mark.integration
    def test_cli_query_mode_json_includes_metadata() -&gt; None:
        """Test that JSON output includes routing metadata."""
        query = "Analyze retention trends in Healthcare"
    
        exit_code, stdout, stderr = run_cli_query(query)
    
        # Should exit successfully
&gt;       assert exit_code == 0, f"CLI failed with stderr: {stderr}"
E       AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour
E         2025-11-08 16:16:22,238 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Analyze retention trends in Healthcare"?
E         
E       assert 1 == 0

tests\integration\orchestration\test_cli_query_mode.py:222: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_cli_query_mode" name="test_cli_query_mode_markdown_format" time="1.461"><failure message="AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour&#10;  2025-11-08 16:16:23,713 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Find anomalies in Construction&quot;?&#10;  &#10;assert 1 == 0&#10; +  where 1 = CompletedProcess(args=['D:\\lmis_int\\.venv\\Scripts\\python.exe', '-m', 'src.qnwis.cli.qnwis_workflow', '--query', 'Find anomalies in Construction', '--format', 'markdown', '--log-level', 'ERROR'], returncode=1, stdout='# QNWIS Analysis: unknown\n\n**Status**: FAILED\n**Request ID**: N/A\n**Timestamp**: 2025-11-08T16:16:23.713243\n\n## Error Summary\n\n**Status**: Failed\n\n**Error**: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Find anomalies in Construction&quot;?\n\n\n## Execution Log\n\n- Started workflow for intent: None\n- Classification: 1 intents, complexity=medium, confidence=0.40\n- WARNING: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Find anomalies in Construction&quot;?\n\n## Reproducibility\n\n**Method**: `error_handler`\n**Timestamp**: 2025-11-08T16:16:23.713243\n\n## Warnings\n\n- Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Find anomalies in Construction&quot;?\n\n', stderr='&lt;frozen runpy&gt;:128: RuntimeWarning: \'src.qnwis.cli.qnwis_workflow\' found in sys.modules after import of package \'src.qnwis.cli\', but prior to execution of \'src.qnwis.cli.qnwis_workflow\'; this may result in unpredictable behaviour\n2025-11-08 16:16:23,713 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Find anomalies in Construction&quot;?\n').returncode">@pytest.mark.integration
    def test_cli_query_mode_markdown_format() -&gt; None:
        """Test CLI with --format markdown."""
        query = "Find anomalies in Construction"
    
        args = [
            sys.executable,
            "-m",
            "src.qnwis.cli.qnwis_workflow",
            "--query",
            query,
            "--format",
            "markdown",
            "--log-level",
            "ERROR",
        ]
    
        result = subprocess.run(
            args,
            capture_output=True,
            text=True,
            cwd=str(Path(__file__).parent.parent.parent.parent),
        )
    
        # Should exit successfully
&gt;       assert result.returncode == 0, f"CLI failed with stderr: {result.stderr}"
E       AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour
E         2025-11-08 16:16:23,713 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Find anomalies in Construction"?
E         
E       assert 1 == 0
E        +  where 1 = CompletedProcess(args=['D:\\lmis_int\\.venv\\Scripts\\python.exe', '-m', 'src.qnwis.cli.qnwis_workflow', '--query', 'Find anomalies in Construction', '--format', 'markdown', '--log-level', 'ERROR'], returncode=1, stdout='# QNWIS Analysis: unknown\n\n**Status**: FAILED\n**Request ID**: N/A\n**Timestamp**: 2025-11-08T16:16:23.713243\n\n## Error Summary\n\n**Status**: Failed\n\n**Error**: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Find anomalies in Construction"?\n\n\n## Execution Log\n\n- Started workflow for intent: None\n- Classification: 1 intents, complexity=medium, confidence=0.40\n- WARNING: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Find anomalies in Construction"?\n\n## Reproducibility\n\n**Method**: `error_handler`\n**Timestamp**: 2025-11-08T16:16:23.713243\n\n## Warnings\n\n- Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Find anomalies in Construction"?\n\n', stderr='&lt;frozen runpy&gt;:128: RuntimeWarning: \'src.qnwis.cli.qnwis_workflow\' found in sys.modules after import of package \'src.qnwis.cli\', but prior to execution of \'src.qnwis.cli.qnwis_workflow\'; this may result in unpredictable behaviour\n2025-11-08 16:16:23,713 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Find anomalies in Construction"?\n').returncode

tests\integration\orchestration\test_cli_query_mode.py:267: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_cli_query_mode" name="test_cli_query_mode_request_id_propagation" time="1.443"><failure message="AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour&#10;  2025-11-08 16:16:25,167 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.00 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Analyze retention in Finance&quot;?&#10;  &#10;assert 1 == 0">@pytest.mark.integration
    def test_cli_query_mode_request_id_propagation() -&gt; None:
        """Test that request_id is propagated through workflow."""
        query = "Analyze retention in Finance"
        request_id = "test-req-12345"
    
        exit_code, stdout, stderr = run_cli_query(
            query,
            extra_args=["--request-id", request_id],
        )
    
        # Should exit successfully
&gt;       assert exit_code == 0, f"CLI failed with stderr: {stderr}"
E       AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour
E         2025-11-08 16:16:25,167 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.00 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Analyze retention in Finance"?
E         
E       assert 1 == 0

tests\integration\orchestration\test_cli_query_mode.py:287: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_cli_query_mode" name="test_cli_query_mode_deterministic_output" time="2.898"><failure message="assert 1 == 0">@pytest.mark.integration
    def test_cli_query_mode_deterministic_output() -&gt; None:
        """Test that same query produces deterministic output."""
        query = "Find correlations in Construction retention over 24 months"
    
        # Run twice
        exit_code1, stdout1, stderr1 = run_cli_query(query)
        exit_code2, stdout2, stderr2 = run_cli_query(query)
    
        # Both should succeed
&gt;       assert exit_code1 == 0
E       assert 1 == 0

tests\integration\orchestration\test_cli_query_mode.py:305: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_cli_query_mode" name="test_cli_query_mode_root_causes" time="1.468"><failure message="AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour&#10;  2025-11-08 16:16:29,633 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Why is retention declining in Construction?&quot;?&#10;  &#10;assert 1 == 0">@pytest.mark.integration
    def test_cli_query_mode_root_causes() -&gt; None:
        """Test CLI with root cause query."""
        query = "Why is retention declining in Construction?"
    
        exit_code, stdout, stderr = run_cli_query(query)
    
        # Should exit successfully
&gt;       assert exit_code == 0, f"CLI failed with stderr: {stderr}"
E       AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour
E         2025-11-08 16:16:29,633 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Why is retention declining in Construction?"?
E         
E       assert 1 == 0

tests\integration\orchestration\test_cli_query_mode.py:329: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_cli_query_mode" name="test_cli_query_mode_best_practices" time="1.436"><failure message="AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour&#10;  2025-11-08 16:16:31,083 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Which companies have best practices for retention in Healthcare?&quot;?&#10;  &#10;assert 1 == 0">@pytest.mark.integration
    def test_cli_query_mode_best_practices() -&gt; None:
        """Test CLI with best practices query."""
        query = "Which companies have best practices for retention in Healthcare?"
    
        exit_code, stdout, stderr = run_cli_query(query)
    
        # Should exit successfully
&gt;       assert exit_code == 0, f"CLI failed with stderr: {stderr}"
E       AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour
E         2025-11-08 16:16:31,083 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Which companies have best practices for retention in Healthcare?"?
E         
E       assert 1 == 0

tests\integration\orchestration\test_cli_query_mode.py:348: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_cli_query_mode" name="test_cli_query_mode_with_sector_override" time="1.440"><failure message="AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour&#10;  2025-11-08 16:16:32,531 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Find anomalies in retention&quot;?&#10;  &#10;assert 1 == 0">@pytest.mark.integration
    def test_cli_query_mode_with_sector_override() -&gt; None:
        """Test CLI query with explicit sector parameter override."""
        query = "Find anomalies in retention"
    
        exit_code, stdout, stderr = run_cli_query(
            query,
            extra_args=["--sector", "Finance"],
        )
    
        # Should exit successfully
&gt;       assert exit_code == 0, f"CLI failed with stderr: {stderr}"
E       AssertionError: CLI failed with stderr: &lt;frozen runpy&gt;:128: RuntimeWarning: 'src.qnwis.cli.qnwis_workflow' found in sys.modules after import of package 'src.qnwis.cli', but prior to execution of 'src.qnwis.cli.qnwis_workflow'; this may result in unpredictable behaviour
E         2025-11-08 16:16:32,531 - src.qnwis.orchestration.nodes.error - ERROR - Handling workflow error: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Find anomalies in retention"?
E         
E       assert 1 == 0

tests\integration\orchestration\test_cli_query_mode.py:370: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationSingle" name="test_single_mode_execution" time="0.001" /><testcase classname="tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationSingle" name="test_single_mode_with_findings" time="0.001" /><testcase classname="tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationParallel" name="test_parallel_mode_execution" time="0.001" /><testcase classname="tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationParallel" name="test_parallel_mode_merges_correctly" time="0.002"><failure message="AssertionError: assert 1 &gt;= 2&#10; +  where 1 = len([Citation(query_id='test_query', dataset_id='test_dataset', locator='test.csv', fields=['field1'], timestamp=None)])&#10; +    where [Citation(query_id='test_query', dataset_id='test_dataset', locator='test.csv', fields=['field1'], timestamp=None)] = OrchestrationResult(ok=True, intent='test.agent1', sections=[ReportSection(title='Executive Summary', body_md='**Agent1 Finding**: Test finding from Agent1'), ReportSection(title='Executive Summary', body_md='**Agent2 Finding**: Test finding from Agent2'), ReportSection(title='Key Findings', body_md='### Agent1 Finding\n\nTest finding from Agent1\n\n**Metrics**: value=42.00'), ReportSection(title='Key Findings', body_md='### Agent2 Finding\n\nTest finding from Agent2\n\n**Metrics**: value=42.00'), ReportSection(title='Evidence', body_md='- **test_dataset** (test_query): test.csv')], citations=[Citation(query_id='test_query', dataset_id='test_dataset', locator='test.csv', fields=['field1'], timestamp=None)], freshness={'test_dataset': Freshness(source='test_dataset', last_updated='2024-01-01', age_days=None, min_timestamp='2024-01-01', max_timestamp='2024-01-01')}, reproducibility=Reproducibility(method='Agent1.run, Agent2.run', params={'merged_from': ['Agent1.run', 'Agent2.run']}, timestamp='2025-11-08T16:16:32.687460'), warnings=[], request_id=None, timestamp='2025-11-08T16:16:32.687460', agent_traces=[{'intent': 'test.agent1', 'agent': 'StubAgent', 'method': 'run', 'elapsed_ms': 0.015700003132224083, 'attempt': 1, 'success': True, 'warnings': []}, {'intent': 'test.agent2', 'agent': 'StubAgent', 'method': 'run', 'elapsed_ms': 0.014599994756281376, 'attempt': 1, 'success': True, 'warnings': []}], cache_stats={}, verification={}, redactions_applied=0, issues_summary={}, audit_manifest=None, audit_id=None, confidence=None).citations">self = &lt;tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationParallel object at 0x000001DB06AF3C90&gt;

    def test_parallel_mode_merges_correctly(self):
        """Test parallel mode merges multiple agent outputs."""
        registry = AgentRegistry()
        agent1 = StubAgent("Agent1")
        agent2 = StubAgent("Agent2")
        registry.register("test.agent1", agent1, "run")
        registry.register("test.agent2", agent2, "run")
    
        coordinator = Coordinator(registry, CoordinationPolicy())
    
        specs = [
            AgentCallSpec(intent="test.agent1", method="run", params={}),
            AgentCallSpec(intent="test.agent2", method="run", params={}),
        ]
    
        waves = coordinator.plan("test.agent1", specs, "parallel")
        results = coordinator.execute(waves, prefetch_cache={}, mode="parallel")
        merged = coordinator.aggregate(results)
    
        assert merged.ok is True
        assert len(merged.sections) &gt;= 2  # At least one section from each agent
        # Should have citations from both agents
&gt;       assert len(merged.citations) &gt;= 2
E       AssertionError: assert 1 &gt;= 2
E        +  where 1 = len([Citation(query_id='test_query', dataset_id='test_dataset', locator='test.csv', fields=['field1'], timestamp=None)])
E        +    where [Citation(query_id='test_query', dataset_id='test_dataset', locator='test.csv', fields=['field1'], timestamp=None)] = OrchestrationResult(ok=True, intent='test.agent1', sections=[ReportSection(title='Executive Summary', body_md='**Agent1 Finding**: Test finding from Agent1'), ReportSection(title='Executive Summary', body_md='**Agent2 Finding**: Test finding from Agent2'), ReportSection(title='Key Findings', body_md='### Agent1 Finding\n\nTest finding from Agent1\n\n**Metrics**: value=42.00'), ReportSection(title='Key Findings', body_md='### Agent2 Finding\n\nTest finding from Agent2\n\n**Metrics**: value=42.00'), ReportSection(title='Evidence', body_md='- **test_dataset** (test_query): test.csv')], citations=[Citation(query_id='test_query', dataset_id='test_dataset', locator='test.csv', fields=['field1'], timestamp=None)], freshness={'test_dataset': Freshness(source='test_dataset', last_updated='2024-01-01', age_days=None, min_timestamp='2024-01-01', max_timestamp='2024-01-01')}, reproducibility=Reproducibility(method='Agent1.run, Agent2.run', params={'merged_from': ['Agent1.run', 'Agent2.run']}, timestamp='2025-11-08T16:16:32.687460'), warnings=[], request_id=None, timestamp='2025-11-08T16:16:32.687460', agent_traces=[{'intent': 'test.agent1', 'agent': 'StubAgent', 'method': 'run', 'elapsed_ms': 0.015700003132224083, 'attempt': 1, 'success': True, 'warnings': []}, {'intent': 'test.agent2', 'agent': 'StubAgent', 'method': 'run', 'elapsed_ms': 0.014599994756281376, 'attempt': 1, 'success': True, 'warnings': []}], cache_stats={}, verification={}, redactions_applied=0, issues_summary={}, audit_manifest=None, audit_id=None, confidence=None).citations

tests\integration\orchestration\test_graph_coordination.py:219: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationSequential" name="test_sequential_mode_execution" time="0.001" /><testcase classname="tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationSequential" name="test_sequential_mode_with_dependencies" time="0.001" /><testcase classname="tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationSequential" name="test_sequential_mode_skips_dependent_on_failure" time="0.001"><failure message="ValueError: per_agent_timeout_ms must be at least 1000ms">self = &lt;tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationSequential object at 0x000001DB07AD5150&gt;

    def test_sequential_mode_skips_dependent_on_failure(self):
        """Test sequential mode skips dependent when prerequisite fails."""
        registry = AgentRegistry()
        failing_agent = StubAgent("FailingAgent", return_findings=False)
        dependent_agent = StubAgent("DependentAgent")
        registry.register("test.failing", failing_agent, "run")
        registry.register("test.dependent", dependent_agent, "run")
    
        # Force failing agent to timeout
&gt;       policy = CoordinationPolicy(per_agent_timeout_ms=1)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\integration\orchestration\test_graph_coordination.py:283: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
&lt;string&gt;:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = CoordinationPolicy(max_parallel=3, crisis_parallel=5, per_agent_timeout_ms=1, total_timeout_ms=60000, strict_merge=False, retry_transient=1)

    def __post_init__(self) -&gt; None:
        """Validate policy constraints."""
        if self.max_parallel &lt; 1:
            raise ValueError("max_parallel must be at least 1")
        if self.crisis_parallel &lt; self.max_parallel:
            raise ValueError("crisis_parallel must be &gt;= max_parallel")
        if self.per_agent_timeout_ms &lt; 1000:
&gt;           raise ValueError("per_agent_timeout_ms must be at least 1000ms")
E           ValueError: per_agent_timeout_ms must be at least 1000ms

src\qnwis\orchestration\policies.py:42: ValueError</failure></testcase><testcase classname="tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationCrisis" name="test_crisis_mode_uses_higher_parallelism" time="0.001" /><testcase classname="tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationPrefetch" name="test_prefetch_populates_cache" time="0.002"><failure message="src.qnwis.orchestration.prefetch.PrefetchError: Prefetch failed for run({'query_id': 'query1'}): 2 validation errors for Provenance&#10;source&#10;  Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&#10;fields&#10;  Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing">self = &lt;tests.integration.orchestration.test_graph_coordination.MockDataClient object at 0x000001DB0AEE7110&gt;
query_id = 'query1'

    def run(self, query_id: str) -&gt; QueryResult:
        """Mock run method."""
        self.calls.append(("run", {"query_id": query_id}))
        return QueryResult(
            query_id=query_id,
            rows=[Row(data={"value": 100})],
&gt;           provenance=Provenance(
                dataset_id="prefetch_dataset",
                locator="prefetch.csv",
                source_format="csv",
            ),
            freshness=Freshness(asof_date="2024-01-01"),
        )
E       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance
E       source
E         Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing
E       fields
E         Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing

tests\integration\orchestration\test_graph_coordination.py:92: ValidationError

The above exception was the direct cause of the following exception:

self = &lt;tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationPrefetch object at 0x000001DB07AD6210&gt;

    def test_prefetch_populates_cache(self):
        """Test that prefetch specs populate cache for agents."""
        client = MockDataClient()
        prefetcher = Prefetcher(client)
    
        specs = [
            PrefetchSpec(
                fn="run",
                params={"query_id": "query1"},
                cache_key="key1",
            ),
            PrefetchSpec(
                fn="get_metrics",
                params={"sector": "health"},
                cache_key="key2",
            ),
        ]
    
&gt;       cache = prefetcher.run(specs)
                ^^^^^^^^^^^^^^^^^^^^^

tests\integration\orchestration\test_graph_coordination.py:357: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;src.qnwis.orchestration.prefetch.Prefetcher object at 0x000001DB0AEE6B10&gt;
specs = [{'cache_key': 'key1', 'fn': 'run', 'params': {'query_id': 'query1'}}, {'cache_key': 'key2', 'fn': 'get_metrics', 'params': {'sector': 'health'}}]

    def run(self, specs: List[PrefetchSpec]) -&gt; Dict[str, QueryResult]:
        """
        Execute prefetch specifications and return cache.
    
        Args:
            specs: List of PrefetchSpec declarations
    
        Returns:
            Dictionary mapping cache_key to QueryResult
    
        Raises:
            PrefetchError: If prefetch fails or times out
        """
        start_time = time.perf_counter()
        cache: Dict[str, QueryResult] = {}
        seen_keys: set[str] = set()
    
        logger.info("Starting prefetch with %d specs", len(specs))
    
        for idx, spec in enumerate(specs):
            # Check timeout
            elapsed_ms = (time.perf_counter() - start_time) * 1000
            if elapsed_ms &gt; self.timeout_ms:
                msg = f"Prefetch timeout after {elapsed_ms:.0f}ms (limit: {self.timeout_ms}ms)"
                logger.error(msg)
                raise PrefetchError(msg)
    
            cache_key = spec["cache_key"]
    
            # Deduplicate by cache_key
            if cache_key in seen_keys:
                logger.debug("Skipping duplicate cache_key: %s", cache_key)
                continue
            seen_keys.add(cache_key)
    
            fn_name = spec["fn"]
            params = spec["params"]
    
            logger.debug(
                "Prefetch [%d/%d]: %s with params=%s",
                idx + 1,
                len(specs),
                fn_name,
                self._sanitize_params(params),
            )
    
            try:
                # Execute via DataClient
                method = getattr(self.client, fn_name, None)
                if method is None:
                    msg = f"DataClient has no method: {fn_name}"
                    logger.error(msg)
                    raise PrefetchError(msg)
    
                if not callable(method):
                    msg = f"DataClient.{fn_name} is not callable"
                    logger.error(msg)
                    raise PrefetchError(msg)
    
                # Call the method
                result = method(**params)
    
                # Validate result type
                if not isinstance(result, QueryResult):
                    msg = (
                        f"DataClient.{fn_name} returned {type(result).__name__}, "
                        "expected QueryResult"
                    )
                    logger.error(msg)
                    raise PrefetchError(msg)
    
                cache[cache_key] = result
                logger.debug("Cached result for key: %s (rows=%d)", cache_key, len(result.rows))
    
                # Write to Redis cache if available
                if self.cache:
                    try:
                        from ..cache.keys import make_cache_key
    
                        qid = getattr(result, "query_id", None)
                        if not isinstance(qid, str) or not qid:
                            raise ValueError(
                                f"Prefetch result from {fn_name} missing query_id."
                            )
                        cache_k, ttl = make_cache_key(
                            fn_name, qid, params, self.cache_version
                        )
                        self.cache.set(cache_k, result, ttl)
                    except Exception as cache_exc:
                        logger.warning(
                            "Failed to write to cache: %s", cache_exc
                        )
    
            except Exception as exc:
                msg = f"Prefetch failed for {fn_name}({params}): {exc}"
                logger.exception(msg)
&gt;               raise PrefetchError(msg) from exc
E               src.qnwis.orchestration.prefetch.PrefetchError: Prefetch failed for run({'query_id': 'query1'}): 2 validation errors for Provenance
E               source
E                 Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]
E                   For further information visit https://errors.pydantic.dev/2.12/v/missing
E               fields
E                 Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]
E                   For further information visit https://errors.pydantic.dev/2.12/v/missing

src\qnwis\orchestration\prefetch.py:153: PrefetchError</failure></testcase><testcase classname="tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationPrefetch" name="test_prefetch_deduplication" time="0.002"><failure message="src.qnwis.orchestration.prefetch.PrefetchError: Prefetch failed for run({'query_id': 'query1'}): 2 validation errors for Provenance&#10;source&#10;  Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&#10;fields&#10;  Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing">self = &lt;tests.integration.orchestration.test_graph_coordination.MockDataClient object at 0x000001DB0A5D5850&gt;
query_id = 'query1'

    def run(self, query_id: str) -&gt; QueryResult:
        """Mock run method."""
        self.calls.append(("run", {"query_id": query_id}))
        return QueryResult(
            query_id=query_id,
            rows=[Row(data={"value": 100})],
&gt;           provenance=Provenance(
                dataset_id="prefetch_dataset",
                locator="prefetch.csv",
                source_format="csv",
            ),
            freshness=Freshness(asof_date="2024-01-01"),
        )
E       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance
E       source
E         Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing
E       fields
E         Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing

tests\integration\orchestration\test_graph_coordination.py:92: ValidationError

The above exception was the direct cause of the following exception:

self = &lt;tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationPrefetch object at 0x000001DB07AD6810&gt;

    def test_prefetch_deduplication(self):
        """Test that prefetch deduplicates by cache_key."""
        client = MockDataClient()
        prefetcher = Prefetcher(client)
    
        specs = [
            PrefetchSpec(
                fn="run",
                params={"query_id": "query1"},
                cache_key="duplicate",
            ),
            PrefetchSpec(
                fn="run",
                params={"query_id": "query2"},
                cache_key="duplicate",
            ),
        ]
    
&gt;       cache = prefetcher.run(specs)
                ^^^^^^^^^^^^^^^^^^^^^

tests\integration\orchestration\test_graph_coordination.py:382: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;src.qnwis.orchestration.prefetch.Prefetcher object at 0x000001DB0A5D5810&gt;
specs = [{'cache_key': 'duplicate', 'fn': 'run', 'params': {'query_id': 'query1'}}, {'cache_key': 'duplicate', 'fn': 'run', 'params': {'query_id': 'query2'}}]

    def run(self, specs: List[PrefetchSpec]) -&gt; Dict[str, QueryResult]:
        """
        Execute prefetch specifications and return cache.
    
        Args:
            specs: List of PrefetchSpec declarations
    
        Returns:
            Dictionary mapping cache_key to QueryResult
    
        Raises:
            PrefetchError: If prefetch fails or times out
        """
        start_time = time.perf_counter()
        cache: Dict[str, QueryResult] = {}
        seen_keys: set[str] = set()
    
        logger.info("Starting prefetch with %d specs", len(specs))
    
        for idx, spec in enumerate(specs):
            # Check timeout
            elapsed_ms = (time.perf_counter() - start_time) * 1000
            if elapsed_ms &gt; self.timeout_ms:
                msg = f"Prefetch timeout after {elapsed_ms:.0f}ms (limit: {self.timeout_ms}ms)"
                logger.error(msg)
                raise PrefetchError(msg)
    
            cache_key = spec["cache_key"]
    
            # Deduplicate by cache_key
            if cache_key in seen_keys:
                logger.debug("Skipping duplicate cache_key: %s", cache_key)
                continue
            seen_keys.add(cache_key)
    
            fn_name = spec["fn"]
            params = spec["params"]
    
            logger.debug(
                "Prefetch [%d/%d]: %s with params=%s",
                idx + 1,
                len(specs),
                fn_name,
                self._sanitize_params(params),
            )
    
            try:
                # Execute via DataClient
                method = getattr(self.client, fn_name, None)
                if method is None:
                    msg = f"DataClient has no method: {fn_name}"
                    logger.error(msg)
                    raise PrefetchError(msg)
    
                if not callable(method):
                    msg = f"DataClient.{fn_name} is not callable"
                    logger.error(msg)
                    raise PrefetchError(msg)
    
                # Call the method
                result = method(**params)
    
                # Validate result type
                if not isinstance(result, QueryResult):
                    msg = (
                        f"DataClient.{fn_name} returned {type(result).__name__}, "
                        "expected QueryResult"
                    )
                    logger.error(msg)
                    raise PrefetchError(msg)
    
                cache[cache_key] = result
                logger.debug("Cached result for key: %s (rows=%d)", cache_key, len(result.rows))
    
                # Write to Redis cache if available
                if self.cache:
                    try:
                        from ..cache.keys import make_cache_key
    
                        qid = getattr(result, "query_id", None)
                        if not isinstance(qid, str) or not qid:
                            raise ValueError(
                                f"Prefetch result from {fn_name} missing query_id."
                            )
                        cache_k, ttl = make_cache_key(
                            fn_name, qid, params, self.cache_version
                        )
                        self.cache.set(cache_k, result, ttl)
                    except Exception as cache_exc:
                        logger.warning(
                            "Failed to write to cache: %s", cache_exc
                        )
    
            except Exception as exc:
                msg = f"Prefetch failed for {fn_name}({params}): {exc}"
                logger.exception(msg)
&gt;               raise PrefetchError(msg) from exc
E               src.qnwis.orchestration.prefetch.PrefetchError: Prefetch failed for run({'query_id': 'query1'}): 2 validation errors for Provenance
E               source
E                 Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]
E                   For further information visit https://errors.pydantic.dev/2.12/v/missing
E               fields
E                 Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]
E                   For further information visit https://errors.pydantic.dev/2.12/v/missing

src\qnwis\orchestration\prefetch.py:153: PrefetchError</failure></testcase><testcase classname="tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationPrefetch" name="test_coordination_with_prefetch_cache" time="0.002"><failure message="src.qnwis.orchestration.prefetch.PrefetchError: Prefetch failed for run({'query_id': 'prefetch_query'}): 2 validation errors for Provenance&#10;source&#10;  Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&#10;fields&#10;  Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing">self = &lt;tests.integration.orchestration.test_graph_coordination.MockDataClient object at 0x000001DB0AEC9790&gt;
query_id = 'prefetch_query'

    def run(self, query_id: str) -&gt; QueryResult:
        """Mock run method."""
        self.calls.append(("run", {"query_id": query_id}))
        return QueryResult(
            query_id=query_id,
            rows=[Row(data={"value": 100})],
&gt;           provenance=Provenance(
                dataset_id="prefetch_dataset",
                locator="prefetch.csv",
                source_format="csv",
            ),
            freshness=Freshness(asof_date="2024-01-01"),
        )
E       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance
E       source
E         Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing
E       fields
E         Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing

tests\integration\orchestration\test_graph_coordination.py:92: ValidationError

The above exception was the direct cause of the following exception:

self = &lt;tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationPrefetch object at 0x000001DB07AD6E10&gt;

    def test_coordination_with_prefetch_cache(self):
        """Test coordinator execution with populated prefetch cache."""
        registry = AgentRegistry()
        agent = StubAgent("TestAgent")
        registry.register("test.agent", agent, "run")
    
        coordinator = Coordinator(registry, CoordinationPolicy())
    
        # Create prefetch cache
        client = MockDataClient()
        prefetcher = Prefetcher(client)
        prefetch_specs = [
            PrefetchSpec(
                fn="run",
                params={"query_id": "prefetch_query"},
                cache_key="prefetch_key",
            )
        ]
&gt;       prefetch_cache = prefetcher.run(prefetch_specs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\integration\orchestration\test_graph_coordination.py:407: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;src.qnwis.orchestration.prefetch.Prefetcher object at 0x000001DB0AEC96D0&gt;
specs = [{'cache_key': 'prefetch_key', 'fn': 'run', 'params': {'query_id': 'prefetch_query'}}]

    def run(self, specs: List[PrefetchSpec]) -&gt; Dict[str, QueryResult]:
        """
        Execute prefetch specifications and return cache.
    
        Args:
            specs: List of PrefetchSpec declarations
    
        Returns:
            Dictionary mapping cache_key to QueryResult
    
        Raises:
            PrefetchError: If prefetch fails or times out
        """
        start_time = time.perf_counter()
        cache: Dict[str, QueryResult] = {}
        seen_keys: set[str] = set()
    
        logger.info("Starting prefetch with %d specs", len(specs))
    
        for idx, spec in enumerate(specs):
            # Check timeout
            elapsed_ms = (time.perf_counter() - start_time) * 1000
            if elapsed_ms &gt; self.timeout_ms:
                msg = f"Prefetch timeout after {elapsed_ms:.0f}ms (limit: {self.timeout_ms}ms)"
                logger.error(msg)
                raise PrefetchError(msg)
    
            cache_key = spec["cache_key"]
    
            # Deduplicate by cache_key
            if cache_key in seen_keys:
                logger.debug("Skipping duplicate cache_key: %s", cache_key)
                continue
            seen_keys.add(cache_key)
    
            fn_name = spec["fn"]
            params = spec["params"]
    
            logger.debug(
                "Prefetch [%d/%d]: %s with params=%s",
                idx + 1,
                len(specs),
                fn_name,
                self._sanitize_params(params),
            )
    
            try:
                # Execute via DataClient
                method = getattr(self.client, fn_name, None)
                if method is None:
                    msg = f"DataClient has no method: {fn_name}"
                    logger.error(msg)
                    raise PrefetchError(msg)
    
                if not callable(method):
                    msg = f"DataClient.{fn_name} is not callable"
                    logger.error(msg)
                    raise PrefetchError(msg)
    
                # Call the method
                result = method(**params)
    
                # Validate result type
                if not isinstance(result, QueryResult):
                    msg = (
                        f"DataClient.{fn_name} returned {type(result).__name__}, "
                        "expected QueryResult"
                    )
                    logger.error(msg)
                    raise PrefetchError(msg)
    
                cache[cache_key] = result
                logger.debug("Cached result for key: %s (rows=%d)", cache_key, len(result.rows))
    
                # Write to Redis cache if available
                if self.cache:
                    try:
                        from ..cache.keys import make_cache_key
    
                        qid = getattr(result, "query_id", None)
                        if not isinstance(qid, str) or not qid:
                            raise ValueError(
                                f"Prefetch result from {fn_name} missing query_id."
                            )
                        cache_k, ttl = make_cache_key(
                            fn_name, qid, params, self.cache_version
                        )
                        self.cache.set(cache_k, result, ttl)
                    except Exception as cache_exc:
                        logger.warning(
                            "Failed to write to cache: %s", cache_exc
                        )
    
            except Exception as exc:
                msg = f"Prefetch failed for {fn_name}({params}): {exc}"
                logger.exception(msg)
&gt;               raise PrefetchError(msg) from exc
E               src.qnwis.orchestration.prefetch.PrefetchError: Prefetch failed for run({'query_id': 'prefetch_query'}): 2 validation errors for Provenance
E               source
E                 Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]
E                   For further information visit https://errors.pydantic.dev/2.12/v/missing
E               fields
E                 Field required [type=missing, input_value={'dataset_id': 'prefetch_... 'source_format': 'csv'}, input_type=dict]
E                   For further information visit https://errors.pydantic.dev/2.12/v/missing

src\qnwis\orchestration\prefetch.py:153: PrefetchError</failure></testcase><testcase classname="tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationTimeout" name="test_agent_timeout_produces_warning" time="0.052" /><testcase classname="tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationMerge" name="test_merge_combines_sections" time="0.001" /><testcase classname="tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationMerge" name="test_merge_deduplicates_citations" time="0.002"><failure message="AssertionError: assert 1 &gt;= 2&#10; +  where 1 = len([Citation(query_id='test_query', dataset_id='test_dataset', locator='test.csv', fields=['field1'], timestamp=None)])&#10; +    where [Citation(query_id='test_query', dataset_id='test_dataset', locator='test.csv', fields=['field1'], timestamp=None)] = OrchestrationResult(ok=True, intent='test.agent1', sections=[ReportSection(title='Executive Summary', body_md='**Agent1 Finding**: Test finding from Agent1'), ReportSection(title='Executive Summary', body_md='**Agent2 Finding**: Test finding from Agent2'), ReportSection(title='Key Findings', body_md='### Agent1 Finding\n\nTest finding from Agent1\n\n**Metrics**: value=42.00'), ReportSection(title='Key Findings', body_md='### Agent2 Finding\n\nTest finding from Agent2\n\n**Metrics**: value=42.00'), ReportSection(title='Evidence', body_md='- **test_dataset** (test_query): test.csv')], citations=[Citation(query_id='test_query', dataset_id='test_dataset', locator='test.csv', fields=['field1'], timestamp=None)], freshness={'test_dataset': Freshness(source='test_dataset', last_updated='2024-01-01', age_days=None, min_timestamp='2024-01-01', max_timestamp='2024-01-01')}, reproducibility=Reproducibility(method='Agent1.run, Agent2.run', params={'merged_from': ['Agent1.run', 'Agent2.run']}, timestamp='2025-11-08T16:16:32.928349'), warnings=[], request_id=None, timestamp='2025-11-08T16:16:32.928349', agent_traces=[{'intent': 'test.agent1', 'agent': 'StubAgent', 'method': 'run', 'elapsed_ms': 0.015600002370774746, 'attempt': 1, 'success': True, 'warnings': []}, {'intent': 'test.agent2', 'agent': 'StubAgent', 'method': 'run', 'elapsed_ms': 0.013399985618889332, 'attempt': 1, 'success': True, 'warnings': []}], cache_stats={}, verification={}, redactions_applied=0, issues_summary={}, audit_manifest=None, audit_id=None, confidence=None).citations">self = &lt;tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationMerge object at 0x000001DB07AE4550&gt;

    def test_merge_deduplicates_citations(self):
        """Test that merge deduplicates citations."""
        registry = AgentRegistry()
        agent1 = StubAgent("Agent1")
        agent2 = StubAgent("Agent2")
        registry.register("test.agent1", agent1, "run")
        registry.register("test.agent2", agent2, "run")
    
        coordinator = Coordinator(registry, CoordinationPolicy())
    
        specs = [
            AgentCallSpec(intent="test.agent1", method="run", params={}),
            AgentCallSpec(intent="test.agent2", method="run", params={}),
        ]
    
        waves = coordinator.plan("test.agent1", specs, "parallel")
        results = coordinator.execute(waves, prefetch_cache={}, mode="parallel")
        merged = coordinator.aggregate(results)
    
        # Should have at least 2 citations (one from each agent)
&gt;       assert len(merged.citations) &gt;= 2
E       AssertionError: assert 1 &gt;= 2
E        +  where 1 = len([Citation(query_id='test_query', dataset_id='test_dataset', locator='test.csv', fields=['field1'], timestamp=None)])
E        +    where [Citation(query_id='test_query', dataset_id='test_dataset', locator='test.csv', fields=['field1'], timestamp=None)] = OrchestrationResult(ok=True, intent='test.agent1', sections=[ReportSection(title='Executive Summary', body_md='**Agent1 Finding**: Test finding from Agent1'), ReportSection(title='Executive Summary', body_md='**Agent2 Finding**: Test finding from Agent2'), ReportSection(title='Key Findings', body_md='### Agent1 Finding\n\nTest finding from Agent1\n\n**Metrics**: value=42.00'), ReportSection(title='Key Findings', body_md='### Agent2 Finding\n\nTest finding from Agent2\n\n**Metrics**: value=42.00'), ReportSection(title='Evidence', body_md='- **test_dataset** (test_query): test.csv')], citations=[Citation(query_id='test_query', dataset_id='test_dataset', locator='test.csv', fields=['field1'], timestamp=None)], freshness={'test_dataset': Freshness(source='test_dataset', last_updated='2024-01-01', age_days=None, min_timestamp='2024-01-01', max_timestamp='2024-01-01')}, reproducibility=Reproducibility(method='Agent1.run, Agent2.run', params={'merged_from': ['Agent1.run', 'Agent2.run']}, timestamp='2025-11-08T16:16:32.928349'), warnings=[], request_id=None, timestamp='2025-11-08T16:16:32.928349', agent_traces=[{'intent': 'test.agent1', 'agent': 'StubAgent', 'method': 'run', 'elapsed_ms': 0.015600002370774746, 'attempt': 1, 'success': True, 'warnings': []}, {'intent': 'test.agent2', 'agent': 'StubAgent', 'method': 'run', 'elapsed_ms': 0.013399985618889332, 'attempt': 1, 'success': True, 'warnings': []}], cache_stats={}, verification={}, redactions_applied=0, issues_summary={}, audit_manifest=None, audit_id=None, confidence=None).citations

tests\integration\orchestration\test_graph_coordination.py:515: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_graph_coordination.TestGraphCoordinationMerge" name="test_merge_tracks_agent_traces" time="0.001" /><testcase classname="tests.integration.orchestration.test_graph_end_to_end" name="test_graph_pattern_anomalies_end_to_end" time="0.001"><error message="failed on setup with &quot;pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance&#10;source&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&#10;fields&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&quot;">@pytest.fixture
    def stubbed_client() -&gt; StubbedDataClient:
        """Fixture providing a stubbed client with synthetic data."""
        client = StubbedDataClient()
    
        # Add synthetic attrition data for pattern detective
        attrition_result = QueryResult(
            query_id="syn_attrition_by_sector_latest",
            rows=[
                Row(data={"sector": "Finance", "attrition_percent": 10.0}),
                Row(data={"sector": "Retail", "attrition_percent": 12.0}),
                Row(data={"sector": "Manufacturing", "attrition_percent": 11.0}),
                Row(data={"sector": "Healthcare", "attrition_percent": 15.0}),
                Row(data={"sector": "Construction", "attrition_percent": 45.0}),  # Anomaly
            ],
&gt;           provenance=Provenance(
                dataset_id="attrition_data",
                locator="data/attrition.csv",
            ),
            freshness=Freshness(
                as_of="2024-01-15T00:00:00Z",
                updated_at="2024-01-15T00:00:00Z",
            ),
        )
E       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance
E       source
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing
E       fields
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing

tests\integration\orchestration\test_graph_end_to_end.py:73: ValidationError</error></testcase><testcase classname="tests.integration.orchestration.test_graph_end_to_end" name="test_graph_pattern_correlation_end_to_end" time="0.001"><error message="failed on setup with &quot;pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance&#10;source&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&#10;fields&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&quot;">@pytest.fixture
    def stubbed_client() -&gt; StubbedDataClient:
        """Fixture providing a stubbed client with synthetic data."""
        client = StubbedDataClient()
    
        # Add synthetic attrition data for pattern detective
        attrition_result = QueryResult(
            query_id="syn_attrition_by_sector_latest",
            rows=[
                Row(data={"sector": "Finance", "attrition_percent": 10.0}),
                Row(data={"sector": "Retail", "attrition_percent": 12.0}),
                Row(data={"sector": "Manufacturing", "attrition_percent": 11.0}),
                Row(data={"sector": "Healthcare", "attrition_percent": 15.0}),
                Row(data={"sector": "Construction", "attrition_percent": 45.0}),  # Anomaly
            ],
&gt;           provenance=Provenance(
                dataset_id="attrition_data",
                locator="data/attrition.csv",
            ),
            freshness=Freshness(
                as_of="2024-01-15T00:00:00Z",
                updated_at="2024-01-15T00:00:00Z",
            ),
        )
E       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance
E       source
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing
E       fields
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing

tests\integration\orchestration\test_graph_end_to_end.py:73: ValidationError</error></testcase><testcase classname="tests.integration.orchestration.test_graph_end_to_end" name="test_graph_strategy_gcc_benchmark_end_to_end" time="0.001"><error message="failed on setup with &quot;pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance&#10;source&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&#10;fields&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&quot;">@pytest.fixture
    def stubbed_client() -&gt; StubbedDataClient:
        """Fixture providing a stubbed client with synthetic data."""
        client = StubbedDataClient()
    
        # Add synthetic attrition data for pattern detective
        attrition_result = QueryResult(
            query_id="syn_attrition_by_sector_latest",
            rows=[
                Row(data={"sector": "Finance", "attrition_percent": 10.0}),
                Row(data={"sector": "Retail", "attrition_percent": 12.0}),
                Row(data={"sector": "Manufacturing", "attrition_percent": 11.0}),
                Row(data={"sector": "Healthcare", "attrition_percent": 15.0}),
                Row(data={"sector": "Construction", "attrition_percent": 45.0}),  # Anomaly
            ],
&gt;           provenance=Provenance(
                dataset_id="attrition_data",
                locator="data/attrition.csv",
            ),
            freshness=Freshness(
                as_of="2024-01-15T00:00:00Z",
                updated_at="2024-01-15T00:00:00Z",
            ),
        )
E       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance
E       source
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing
E       fields
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing

tests\integration\orchestration\test_graph_end_to_end.py:73: ValidationError</error></testcase><testcase classname="tests.integration.orchestration.test_graph_end_to_end" name="test_graph_handles_unknown_intent" time="0.001"><error message="failed on setup with &quot;pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance&#10;source&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&#10;fields&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&quot;">@pytest.fixture
    def stubbed_client() -&gt; StubbedDataClient:
        """Fixture providing a stubbed client with synthetic data."""
        client = StubbedDataClient()
    
        # Add synthetic attrition data for pattern detective
        attrition_result = QueryResult(
            query_id="syn_attrition_by_sector_latest",
            rows=[
                Row(data={"sector": "Finance", "attrition_percent": 10.0}),
                Row(data={"sector": "Retail", "attrition_percent": 12.0}),
                Row(data={"sector": "Manufacturing", "attrition_percent": 11.0}),
                Row(data={"sector": "Healthcare", "attrition_percent": 15.0}),
                Row(data={"sector": "Construction", "attrition_percent": 45.0}),  # Anomaly
            ],
&gt;           provenance=Provenance(
                dataset_id="attrition_data",
                locator="data/attrition.csv",
            ),
            freshness=Freshness(
                as_of="2024-01-15T00:00:00Z",
                updated_at="2024-01-15T00:00:00Z",
            ),
        )
E       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance
E       source
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing
E       fields
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing

tests\integration\orchestration\test_graph_end_to_end.py:73: ValidationError</error></testcase><testcase classname="tests.integration.orchestration.test_graph_end_to_end" name="test_graph_handles_agent_errors_gracefully" time="0.001"><error message="failed on setup with &quot;pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance&#10;source&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&#10;fields&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&quot;">@pytest.fixture
    def stubbed_client() -&gt; StubbedDataClient:
        """Fixture providing a stubbed client with synthetic data."""
        client = StubbedDataClient()
    
        # Add synthetic attrition data for pattern detective
        attrition_result = QueryResult(
            query_id="syn_attrition_by_sector_latest",
            rows=[
                Row(data={"sector": "Finance", "attrition_percent": 10.0}),
                Row(data={"sector": "Retail", "attrition_percent": 12.0}),
                Row(data={"sector": "Manufacturing", "attrition_percent": 11.0}),
                Row(data={"sector": "Healthcare", "attrition_percent": 15.0}),
                Row(data={"sector": "Construction", "attrition_percent": 45.0}),  # Anomaly
            ],
&gt;           provenance=Provenance(
                dataset_id="attrition_data",
                locator="data/attrition.csv",
            ),
            freshness=Freshness(
                as_of="2024-01-15T00:00:00Z",
                updated_at="2024-01-15T00:00:00Z",
            ),
        )
E       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance
E       source
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing
E       fields
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing

tests\integration\orchestration\test_graph_end_to_end.py:73: ValidationError</error></testcase><testcase classname="tests.integration.orchestration.test_graph_end_to_end" name="test_graph_multiple_sequential_runs" time="0.001"><error message="failed on setup with &quot;pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance&#10;source&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&#10;fields&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&quot;">@pytest.fixture
    def stubbed_client() -&gt; StubbedDataClient:
        """Fixture providing a stubbed client with synthetic data."""
        client = StubbedDataClient()
    
        # Add synthetic attrition data for pattern detective
        attrition_result = QueryResult(
            query_id="syn_attrition_by_sector_latest",
            rows=[
                Row(data={"sector": "Finance", "attrition_percent": 10.0}),
                Row(data={"sector": "Retail", "attrition_percent": 12.0}),
                Row(data={"sector": "Manufacturing", "attrition_percent": 11.0}),
                Row(data={"sector": "Healthcare", "attrition_percent": 15.0}),
                Row(data={"sector": "Construction", "attrition_percent": 45.0}),  # Anomaly
            ],
&gt;           provenance=Provenance(
                dataset_id="attrition_data",
                locator="data/attrition.csv",
            ),
            freshness=Freshness(
                as_of="2024-01-15T00:00:00Z",
                updated_at="2024-01-15T00:00:00Z",
            ),
        )
E       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance
E       source
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing
E       fields
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing

tests\integration\orchestration\test_graph_end_to_end.py:73: ValidationError</error></testcase><testcase classname="tests.integration.orchestration.test_graph_end_to_end" name="test_graph_with_custom_config" time="0.001"><error message="failed on setup with &quot;pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance&#10;source&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&#10;fields&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&quot;">@pytest.fixture
    def stubbed_client() -&gt; StubbedDataClient:
        """Fixture providing a stubbed client with synthetic data."""
        client = StubbedDataClient()
    
        # Add synthetic attrition data for pattern detective
        attrition_result = QueryResult(
            query_id="syn_attrition_by_sector_latest",
            rows=[
                Row(data={"sector": "Finance", "attrition_percent": 10.0}),
                Row(data={"sector": "Retail", "attrition_percent": 12.0}),
                Row(data={"sector": "Manufacturing", "attrition_percent": 11.0}),
                Row(data={"sector": "Healthcare", "attrition_percent": 15.0}),
                Row(data={"sector": "Construction", "attrition_percent": 45.0}),  # Anomaly
            ],
&gt;           provenance=Provenance(
                dataset_id="attrition_data",
                locator="data/attrition.csv",
            ),
            freshness=Freshness(
                as_of="2024-01-15T00:00:00Z",
                updated_at="2024-01-15T00:00:00Z",
            ),
        )
E       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance
E       source
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing
E       fields
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing

tests\integration\orchestration\test_graph_end_to_end.py:73: ValidationError</error></testcase><testcase classname="tests.integration.orchestration.test_graph_end_to_end" name="test_graph_preserves_request_id" time="0.001"><error message="failed on setup with &quot;pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance&#10;source&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&#10;fields&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&quot;">@pytest.fixture
    def stubbed_client() -&gt; StubbedDataClient:
        """Fixture providing a stubbed client with synthetic data."""
        client = StubbedDataClient()
    
        # Add synthetic attrition data for pattern detective
        attrition_result = QueryResult(
            query_id="syn_attrition_by_sector_latest",
            rows=[
                Row(data={"sector": "Finance", "attrition_percent": 10.0}),
                Row(data={"sector": "Retail", "attrition_percent": 12.0}),
                Row(data={"sector": "Manufacturing", "attrition_percent": 11.0}),
                Row(data={"sector": "Healthcare", "attrition_percent": 15.0}),
                Row(data={"sector": "Construction", "attrition_percent": 45.0}),  # Anomaly
            ],
&gt;           provenance=Provenance(
                dataset_id="attrition_data",
                locator="data/attrition.csv",
            ),
            freshness=Freshness(
                as_of="2024-01-15T00:00:00Z",
                updated_at="2024-01-15T00:00:00Z",
            ),
        )
E       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance
E       source
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing
E       fields
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing

tests\integration\orchestration\test_graph_end_to_end.py:73: ValidationError</error></testcase><testcase classname="tests.integration.orchestration.test_graph_end_to_end" name="test_graph_deterministic_output" time="0.001"><error message="failed on setup with &quot;pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance&#10;source&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&#10;fields&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&quot;">@pytest.fixture
    def stubbed_client() -&gt; StubbedDataClient:
        """Fixture providing a stubbed client with synthetic data."""
        client = StubbedDataClient()
    
        # Add synthetic attrition data for pattern detective
        attrition_result = QueryResult(
            query_id="syn_attrition_by_sector_latest",
            rows=[
                Row(data={"sector": "Finance", "attrition_percent": 10.0}),
                Row(data={"sector": "Retail", "attrition_percent": 12.0}),
                Row(data={"sector": "Manufacturing", "attrition_percent": 11.0}),
                Row(data={"sector": "Healthcare", "attrition_percent": 15.0}),
                Row(data={"sector": "Construction", "attrition_percent": 45.0}),  # Anomaly
            ],
&gt;           provenance=Provenance(
                dataset_id="attrition_data",
                locator="data/attrition.csv",
            ),
            freshness=Freshness(
                as_of="2024-01-15T00:00:00Z",
                updated_at="2024-01-15T00:00:00Z",
            ),
        )
E       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance
E       source
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing
E       fields
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing

tests\integration\orchestration\test_graph_end_to_end.py:73: ValidationError</error></testcase><testcase classname="tests.integration.orchestration.test_graph_end_to_end" name="test_graph_citation_quality" time="0.001"><error message="failed on setup with &quot;pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance&#10;source&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&#10;fields&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&quot;">@pytest.fixture
    def stubbed_client() -&gt; StubbedDataClient:
        """Fixture providing a stubbed client with synthetic data."""
        client = StubbedDataClient()
    
        # Add synthetic attrition data for pattern detective
        attrition_result = QueryResult(
            query_id="syn_attrition_by_sector_latest",
            rows=[
                Row(data={"sector": "Finance", "attrition_percent": 10.0}),
                Row(data={"sector": "Retail", "attrition_percent": 12.0}),
                Row(data={"sector": "Manufacturing", "attrition_percent": 11.0}),
                Row(data={"sector": "Healthcare", "attrition_percent": 15.0}),
                Row(data={"sector": "Construction", "attrition_percent": 45.0}),  # Anomaly
            ],
&gt;           provenance=Provenance(
                dataset_id="attrition_data",
                locator="data/attrition.csv",
            ),
            freshness=Freshness(
                as_of="2024-01-15T00:00:00Z",
                updated_at="2024-01-15T00:00:00Z",
            ),
        )
E       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance
E       source
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing
E       fields
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing

tests\integration\orchestration\test_graph_end_to_end.py:73: ValidationError</error></testcase><testcase classname="tests.integration.orchestration.test_graph_end_to_end" name="test_graph_freshness_metadata" time="0.001"><error message="failed on setup with &quot;pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance&#10;source&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&#10;fields&#10;  Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/missing&quot;">@pytest.fixture
    def stubbed_client() -&gt; StubbedDataClient:
        """Fixture providing a stubbed client with synthetic data."""
        client = StubbedDataClient()
    
        # Add synthetic attrition data for pattern detective
        attrition_result = QueryResult(
            query_id="syn_attrition_by_sector_latest",
            rows=[
                Row(data={"sector": "Finance", "attrition_percent": 10.0}),
                Row(data={"sector": "Retail", "attrition_percent": 12.0}),
                Row(data={"sector": "Manufacturing", "attrition_percent": 11.0}),
                Row(data={"sector": "Healthcare", "attrition_percent": 15.0}),
                Row(data={"sector": "Construction", "attrition_percent": 45.0}),  # Anomaly
            ],
&gt;           provenance=Provenance(
                dataset_id="attrition_data",
                locator="data/attrition.csv",
            ),
            freshness=Freshness(
                as_of="2024-01-15T00:00:00Z",
                updated_at="2024-01-15T00:00:00Z",
            ),
        )
E       pydantic_core._pydantic_core.ValidationError: 2 validation errors for Provenance
E       source
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing
E       fields
E         Field required [type=missing, input_value={'dataset_id': 'attrition...': 'data/attrition.csv'}, input_type=dict]
E           For further information visit https://errors.pydantic.dev/2.12/v/missing

tests\integration\orchestration\test_graph_end_to_end.py:73: ValidationError</error></testcase><testcase classname="tests.integration.orchestration.test_graph_routing" name="test_graph_routing_pattern_anomalies" time="0.146"><failure message="assert False is True&#10; +  where False = OrchestrationResult(ok=False, intent='unknown', sections=[ReportSection(title='Error Summary', body_md='**Status**: Failed\n\n**Error**: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Find anomalies in Construction retention over last 24 months&quot;?\n'), ReportSection(title='Execution Log', body_md='- Started workflow for intent: None\n- Classification: 1 intents, complexity=medium, confidence=0.40\n- WARNING: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Find anomalies in Construction retention over last 24 months&quot;?')], citations=[], freshness={}, reproducibility=Reproducibility(method='error_handler', params={}, timestamp='2025-11-08T16:16:33.291130'), warnings=['Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Find anomalies in Construction retention over last 24 months&quot;?'], request_id=None, timestamp='2025-11-08T16:16:33.291130', agent_traces=[], cache_stats={}, verification={}, redactions_applied=0, issues_summary={}, audit_manifest=None, audit_id=None, confidence=None).ok">registry_with_fake_agents = (&lt;src.qnwis.orchestration.registry.AgentRegistry object at 0x000001DB0AEBBE50&gt;, &lt;tests.integration.orchestration.test_...000001DB0A970290&gt;, &lt;tests.integration.orchestration.test_graph_routing.FakeStrategyAgent object at 0x000001DB0AEB84D0&gt;)

    def test_graph_routing_pattern_anomalies(
        registry_with_fake_agents: tuple[AgentRegistry, FakePatternAgent, FakeStrategyAgent]
    ) -&gt; None:
        """Test graph routing for pattern.anomalies intent."""
        registry, pattern_agent, strategy_agent = registry_with_fake_agents
    
        config: dict[str, Any] = {"enabled_intents": list(registry.intents())}
        graph = create_graph(registry, config)
    
        query = "Find anomalies in Construction retention over last 24 months"
        task = OrchestrationTask(query_text=query, params={})
    
        result = graph.run(task)
    
        # Should succeed
&gt;       assert result.ok is True
E       assert False is True
E        +  where False = OrchestrationResult(ok=False, intent='unknown', sections=[ReportSection(title='Error Summary', body_md='**Status**: Failed\n\n**Error**: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Find anomalies in Construction retention over last 24 months"?\n'), ReportSection(title='Execution Log', body_md='- Started workflow for intent: None\n- Classification: 1 intents, complexity=medium, confidence=0.40\n- WARNING: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Find anomalies in Construction retention over last 24 months"?')], citations=[], freshness={}, reproducibility=Reproducibility(method='error_handler', params={}, timestamp='2025-11-08T16:16:33.291130'), warnings=['Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Find anomalies in Construction retention over last 24 months"?'], request_id=None, timestamp='2025-11-08T16:16:33.291130', agent_traces=[], cache_stats={}, verification={}, redactions_applied=0, issues_summary={}, audit_manifest=None, audit_id=None, confidence=None).ok

tests\integration\orchestration\test_graph_routing.py:237: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_graph_routing" name="test_graph_routing_pattern_correlation" time="0.016"><failure message="assert False is True&#10; +  where False = OrchestrationResult(ok=False, intent='unknown', sections=[ReportSection(title='Error Summary', body_md='**Status**: Failed\n\n**Error**: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Is there a correlation between salary and retention in Healthcare?&quot;?\n'), ReportSection(title='Execution Log', body_md='- Started workflow for intent: None\n- Classification: 1 intents, complexity=medium, confidence=0.40\n- WARNING: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Is there a correlation between salary and retention in Healthcare?&quot;?')], citations=[], freshness={}, reproducibility=Reproducibility(method='error_handler', params={}, timestamp='2025-11-08T16:16:33.322246'), warnings=['Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Is there a correlation between salary and retention in Healthcare?&quot;?'], request_id=None, timestamp='2025-11-08T16:16:33.322246', agent_traces=[], cache_stats={}, verification={}, redactions_applied=0, issues_summary={}, audit_manifest=None, audit_id=None, confidence=None).ok">registry_with_fake_agents = (&lt;src.qnwis.orchestration.registry.AgentRegistry object at 0x000001DB0AFCB3D0&gt;, &lt;tests.integration.orchestration.test_...000001DB0AFCBED0&gt;, &lt;tests.integration.orchestration.test_graph_routing.FakeStrategyAgent object at 0x000001DB0AFC8550&gt;)

    def test_graph_routing_pattern_correlation(
        registry_with_fake_agents: tuple[AgentRegistry, FakePatternAgent, FakeStrategyAgent]
    ) -&gt; None:
        """Test graph routing for pattern.correlation intent."""
        registry, pattern_agent, strategy_agent = registry_with_fake_agents
    
        config: dict[str, Any] = {"enabled_intents": list(registry.intents())}
        graph = create_graph(registry, config)
    
        query = "Is there a correlation between salary and retention in Healthcare?"
        task = OrchestrationTask(query_text=query, params={})
    
        result = graph.run(task)
    
        # Should succeed
&gt;       assert result.ok is True
E       assert False is True
E        +  where False = OrchestrationResult(ok=False, intent='unknown', sections=[ReportSection(title='Error Summary', body_md='**Status**: Failed\n\n**Error**: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Is there a correlation between salary and retention in Healthcare?"?\n'), ReportSection(title='Execution Log', body_md='- Started workflow for intent: None\n- Classification: 1 intents, complexity=medium, confidence=0.40\n- WARNING: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Is there a correlation between salary and retention in Healthcare?"?')], citations=[], freshness={}, reproducibility=Reproducibility(method='error_handler', params={}, timestamp='2025-11-08T16:16:33.322246'), warnings=['Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Is there a correlation between salary and retention in Healthcare?"?'], request_id=None, timestamp='2025-11-08T16:16:33.322246', agent_traces=[], cache_stats={}, verification={}, redactions_applied=0, issues_summary={}, audit_manifest=None, audit_id=None, confidence=None).ok

tests\integration\orchestration\test_graph_routing.py:267: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_graph_routing" name="test_graph_routing_pattern_root_causes" time="0.016"><failure message="assert False is True&#10; +  where False = OrchestrationResult(ok=False, intent='unknown', sections=[ReportSection(title='Error Summary', body_md='**Status**: Failed\n\n**Error**: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Why is retention declining in Construction sector?&quot;?\n'), ReportSection(title='Execution Log', body_md='- Started workflow for intent: None\n- Classification: 1 intents, complexity=medium, confidence=0.40\n- WARNING: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Why is retention declining in Construction sector?&quot;?')], citations=[], freshness={}, reproducibility=Reproducibility(method='error_handler', params={}, timestamp='2025-11-08T16:16:33.353296'), warnings=['Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Why is retention declining in Construction sector?&quot;?'], request_id=None, timestamp='2025-11-08T16:16:33.353296', agent_traces=[], cache_stats={}, verification={}, redactions_applied=0, issues_summary={}, audit_manifest=None, audit_id=None, confidence=None).ok">registry_with_fake_agents = (&lt;src.qnwis.orchestration.registry.AgentRegistry object at 0x000001DB0AFBE450&gt;, &lt;tests.integration.orchestration.test_...000001DB0AFBED10&gt;, &lt;tests.integration.orchestration.test_graph_routing.FakeStrategyAgent object at 0x000001DB0AFBF990&gt;)

    def test_graph_routing_pattern_root_causes(
        registry_with_fake_agents: tuple[AgentRegistry, FakePatternAgent, FakeStrategyAgent]
    ) -&gt; None:
        """Test graph routing for pattern.root_causes intent."""
        registry, pattern_agent, strategy_agent = registry_with_fake_agents
    
        config: dict[str, Any] = {"enabled_intents": list(registry.intents())}
        graph = create_graph(registry, config)
    
        query = "Why is retention declining in Construction sector?"
        task = OrchestrationTask(query_text=query, params={})
    
        result = graph.run(task)
    
        # Should succeed
&gt;       assert result.ok is True
E       assert False is True
E        +  where False = OrchestrationResult(ok=False, intent='unknown', sections=[ReportSection(title='Error Summary', body_md='**Status**: Failed\n\n**Error**: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Why is retention declining in Construction sector?"?\n'), ReportSection(title='Execution Log', body_md='- Started workflow for intent: None\n- Classification: 1 intents, complexity=medium, confidence=0.40\n- WARNING: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Why is retention declining in Construction sector?"?')], citations=[], freshness={}, reproducibility=Reproducibility(method='error_handler', params={}, timestamp='2025-11-08T16:16:33.353296'), warnings=['Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Why is retention declining in Construction sector?"?'], request_id=None, timestamp='2025-11-08T16:16:33.353296', agent_traces=[], cache_stats={}, verification={}, redactions_applied=0, issues_summary={}, audit_manifest=None, audit_id=None, confidence=None).ok

tests\integration\orchestration\test_graph_routing.py:291: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_graph_routing" name="test_graph_routing_pattern_best_practices" time="0.016"><failure message="assert False is True&#10; +  where False = OrchestrationResult(ok=False, intent='unknown', sections=[ReportSection(title='Error Summary', body_md='**Status**: Failed\n\n**Error**: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Which companies have best practices for retention in Healthcare?&quot;?\n'), ReportSection(title='Execution Log', body_md='- Started workflow for intent: None\n- Classification: 1 intents, complexity=medium, confidence=0.40\n- WARNING: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Which companies have best practices for retention in Healthcare?&quot;?')], citations=[], freshness={}, reproducibility=Reproducibility(method='error_handler', params={}, timestamp='2025-11-08T16:16:33.384349'), warnings=['Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Which companies have best practices for retention in Healthcare?&quot;?'], request_id=None, timestamp='2025-11-08T16:16:33.384349', agent_traces=[], cache_stats={}, verification={}, redactions_applied=0, issues_summary={}, audit_manifest=None, audit_id=None, confidence=None).ok">registry_with_fake_agents = (&lt;src.qnwis.orchestration.registry.AgentRegistry object at 0x000001DB0AFCA610&gt;, &lt;tests.integration.orchestration.test_...000001DB0AFBD350&gt;, &lt;tests.integration.orchestration.test_graph_routing.FakeStrategyAgent object at 0x000001DB0AFBE610&gt;)

    def test_graph_routing_pattern_best_practices(
        registry_with_fake_agents: tuple[AgentRegistry, FakePatternAgent, FakeStrategyAgent]
    ) -&gt; None:
        """Test graph routing for pattern.best_practices intent."""
        registry, pattern_agent, strategy_agent = registry_with_fake_agents
    
        config: dict[str, Any] = {"enabled_intents": list(registry.intents())}
        graph = create_graph(registry, config)
    
        query = "Which companies have best practices for retention in Healthcare?"
        task = OrchestrationTask(query_text=query, params={})
    
        result = graph.run(task)
    
        # Should succeed
&gt;       assert result.ok is True
E       assert False is True
E        +  where False = OrchestrationResult(ok=False, intent='unknown', sections=[ReportSection(title='Error Summary', body_md='**Status**: Failed\n\n**Error**: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Which companies have best practices for retention in Healthcare?"?\n'), ReportSection(title='Execution Log', body_md='- Started workflow for intent: None\n- Classification: 1 intents, complexity=medium, confidence=0.40\n- WARNING: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Which companies have best practices for retention in Healthcare?"?')], citations=[], freshness={}, reproducibility=Reproducibility(method='error_handler', params={}, timestamp='2025-11-08T16:16:33.384349'), warnings=['Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Which companies have best practices for retention in Healthcare?"?'], request_id=None, timestamp='2025-11-08T16:16:33.384349', agent_traces=[], cache_stats={}, verification={}, redactions_applied=0, issues_summary={}, audit_manifest=None, audit_id=None, confidence=None).ok

tests\integration\orchestration\test_graph_routing.py:312: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_graph_routing" name="test_graph_routing_strategy_gcc_benchmark" time="0.057" /><testcase classname="tests.integration.orchestration.test_graph_routing" name="test_graph_routing_strategy_talent_competition" time="0.017" /><testcase classname="tests.integration.orchestration.test_graph_routing" name="test_graph_routing_strategy_vision2030" time="0.017" /><testcase classname="tests.integration.orchestration.test_graph_routing" name="test_graph_routing_prefetch_present_not_executed" time="0.016"><failure message="assert False is True&#10; +  where False = OrchestrationResult(ok=False, intent='unknown', sections=[ReportSection(title='Error Summary', body_md='**Status**: Failed\n\n**Error**: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Analyze retention trends in Construction over 36 months&quot;?\n'), ReportSection(title='Execution Log', body_md='- Started workflow for intent: None\n- Classification: 1 intents, complexity=medium, confidence=0.40\n- WARNING: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Analyze retention trends in Construction over 36 months&quot;?')], citations=[], freshness={}, reproducibility=Reproducibility(method='error_handler', params={}, timestamp='2025-11-08T16:16:33.509090'), warnings=['Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Analyze retention trends in Construction over 36 months&quot;?'], request_id=None, timestamp='2025-11-08T16:16:33.509090', agent_traces=[], cache_stats={}, verification={}, redactions_applied=0, issues_summary={}, audit_manifest=None, audit_id=None, confidence=None).ok">registry_with_fake_agents = (&lt;src.qnwis.orchestration.registry.AgentRegistry object at 0x000001DB0AFD7250&gt;, &lt;tests.integration.orchestration.test_...000001DB0AFB7490&gt;, &lt;tests.integration.orchestration.test_graph_routing.FakeStrategyAgent object at 0x000001DB0AFB7D10&gt;)

    def test_graph_routing_prefetch_present_not_executed(
        registry_with_fake_agents: tuple[AgentRegistry, FakePatternAgent, FakeStrategyAgent]
    ) -&gt; None:
        """Test that RoutingDecision.prefetch is present but not executed."""
        registry, pattern_agent, strategy_agent = registry_with_fake_agents
    
        config: dict[str, Any] = {"enabled_intents": list(registry.intents())}
        graph = create_graph(registry, config)
    
        query = "Analyze retention trends in Construction over 36 months"
        task = OrchestrationTask(query_text=query, params={})
    
        result = graph.run(task)
    
        # Should succeed
&gt;       assert result.ok is True
E       assert False is True
E        +  where False = OrchestrationResult(ok=False, intent='unknown', sections=[ReportSection(title='Error Summary', body_md='**Status**: Failed\n\n**Error**: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Analyze retention trends in Construction over 36 months"?\n'), ReportSection(title='Execution Log', body_md='- Started workflow for intent: None\n- Classification: 1 intents, complexity=medium, confidence=0.40\n- WARNING: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Analyze retention trends in Construction over 36 months"?')], citations=[], freshness={}, reproducibility=Reproducibility(method='error_handler', params={}, timestamp='2025-11-08T16:16:33.509090'), warnings=['Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Analyze retention trends in Construction over 36 months"?'], request_id=None, timestamp='2025-11-08T16:16:33.509090', agent_traces=[], cache_stats={}, verification={}, redactions_applied=0, issues_summary={}, audit_manifest=None, audit_id=None, confidence=None).ok

tests\integration\orchestration\test_graph_routing.py:399: AssertionError</failure></testcase><testcase classname="tests.integration.orchestration.test_graph_routing" name="test_graph_routing_explicit_intent_still_works" time="0.016" /><testcase classname="tests.integration.orchestration.test_graph_routing" name="test_graph_routing_low_confidence_fails_gracefully" time="0.015" /><testcase classname="tests.integration.orchestration.test_graph_routing" name="test_graph_routing_multiple_intents_parallel_mode" time="0.016"><failure message="assert False is True&#10; +  where False = OrchestrationResult(ok=False, intent='unknown', sections=[ReportSection(title='Error Summary', body_md='**Status**: Failed\n\n**Error**: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Find outliers and relationships in Construction retention last 24 months&quot;?\n'), ReportSection(title='Execution Log', body_md='- Started workflow for intent: None\n- Classification: 3 intents, complexity=medium, confidence=0.40\n- WARNING: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Find outliers and relationships in Construction retention last 24 months&quot;?')], citations=[], freshness={}, reproducibility=Reproducibility(method='error_handler', params={}, timestamp='2025-11-08T16:16:33.574072'), warnings=['Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for &quot;Find outliers and relationships in Construction retention last 24 months&quot;?'], request_id=None, timestamp='2025-11-08T16:16:33.574072', agent_traces=[], cache_stats={}, verification={}, redactions_applied=0, issues_summary={}, audit_manifest=None, audit_id=None, confidence=None).ok">registry_with_fake_agents = (&lt;src.qnwis.orchestration.registry.AgentRegistry object at 0x000001DB0AF21D90&gt;, &lt;tests.integration.orchestration.test_...000001DB0AF22810&gt;, &lt;tests.integration.orchestration.test_graph_routing.FakeStrategyAgent object at 0x000001DB0AF21B50&gt;)

    def test_graph_routing_multiple_intents_parallel_mode(
        registry_with_fake_agents: tuple[AgentRegistry, FakePatternAgent, FakeStrategyAgent]
    ) -&gt; None:
        """Test parallel mode when multiple intents tie."""
        registry, pattern_agent, strategy_agent = registry_with_fake_agents
    
        config: dict[str, Any] = {"enabled_intents": list(registry.intents())}
        graph = create_graph(registry, config)
    
        # Query that matches both anomalies and correlations
        query = "Find outliers and relationships in Construction retention last 24 months"
        task = OrchestrationTask(query_text=query, params={})
    
        result = graph.run(task)
    
        # Should succeed (even if parallel mode not fully implemented, should execute primary)
&gt;       assert result.ok is True
E       assert False is True
E        +  where False = OrchestrationResult(ok=False, intent='unknown', sections=[ReportSection(title='Error Summary', body_md='**Status**: Failed\n\n**Error**: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Find outliers and relationships in Construction retention last 24 months"?\n'), ReportSection(title='Execution Log', body_md='- Started workflow for intent: None\n- Classification: 3 intents, complexity=medium, confidence=0.40\n- WARNING: Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Find outliers and relationships in Construction retention last 24 months"?')], citations=[], freshness={}, reproducibility=Reproducibility(method='error_handler', params={}, timestamp='2025-11-08T16:16:33.574072'), warnings=['Clarification required (confidence 0.40 &lt; 0.55). Could you clarify the primary labour market metric or sector for "Find outliers and relationships in Construction retention last 24 months"?'], request_id=None, timestamp='2025-11-08T16:16:33.574072', agent_traces=[], cache_stats={}, verification={}, redactions_applied=0, issues_summary={}, audit_manifest=None, audit_id=None, confidence=None).ok

tests\integration\orchestration\test_graph_routing.py:478: AssertionError</failure></testcase><testcase classname="tests.integration.perf.test_mv_job.TestMVRefreshJob" name="test_job_loads_definitions_and_materializes" time="0.024" /><testcase classname="tests.integration.perf.test_mv_job.TestMVRefreshJob" name="test_job_uses_rendered_sql_from_registry" time="0.013" /><testcase classname="tests.integration.perf.test_mv_job.TestMVRefreshJob" name="test_job_creates_indexes_for_each_mv" time="0.013" /><testcase classname="tests.integration.perf.test_mv_job.TestMVRefreshJob" name="test_job_calls_refresh_concurrently" time="0.013" /><testcase classname="tests.integration.perf.test_mv_job.TestMVRefreshJob" name="test_job_validates_queries_exist_in_registry" time="0.013" /><testcase classname="tests.integration.perf.test_mv_job.TestMVRefreshJob" name="test_job_handles_empty_params" time="0.017" /><testcase classname="tests.integration.perf.test_mv_job.TestMVRefreshJob" name="test_job_output_json_format" time="0.013" /><testcase classname="tests.integration.perf.test_mv_job.TestMVRefreshJob" name="test_job_uses_materializer_correctly" time="0.014" /><testcase classname="tests.integration.perf.test_mv_job.TestMVRefreshJob" name="test_job_passes_params_to_render_select" time="0.013" /><testcase classname="tests.integration.perf.test_mv_job.TestMVRefreshJob" name="test_job_handles_single_mv" time="0.017" /><testcase classname="tests.integration.perf.test_mv_job.TestMVRefreshJob" name="test_job_handles_mv_with_no_indexes" time="0.016" /><testcase classname="tests.integration.perf.test_prefetch_cache_integration.TestPrefetchCacheIntegration" name="test_prefetch_writes_to_cache" time="0.005" /><testcase classname="tests.integration.perf.test_prefetch_cache_integration.TestPrefetchCacheIntegration" name="test_cached_client_reads_from_cache_after_prefetch" time="0.004" /><testcase classname="tests.integration.perf.test_prefetch_cache_integration.TestPrefetchCacheIntegration" name="test_prefetch_deduplicates_by_cache_key" time="0.004" /><testcase classname="tests.integration.perf.test_prefetch_cache_integration.TestPrefetchCacheIntegration" name="test_prefetch_timeout_raises_error" time="0.105" /><testcase classname="tests.integration.perf.test_prefetch_cache_integration.TestPrefetchCacheIntegration" name="test_prefetch_invalid_method_raises_error" time="0.004" /><testcase classname="tests.integration.perf.test_prefetch_cache_integration.TestPrefetchCacheIntegration" name="test_prefetch_handles_cache_write_failure_gracefully" time="0.004" /><testcase classname="tests.integration.perf.test_prefetch_cache_integration.TestPrefetchCacheIntegration" name="test_cached_client_falls_back_to_delegate_on_cache_miss" time="0.004" /><testcase classname="tests.integration.test_agents_graphs" name="test_graph_runs_with_deterministic_client" time="0.012" /><testcase classname="tests.integration.test_agents_graphs" name="test_graph_with_multiple_queries" time="0.011" /><testcase classname="tests.integration.test_agents_graphs" name="test_graph_with_empty_results" time="0.011" /><testcase classname="tests.integration.test_api_briefing" name="test_minister_briefing_endpoint" time="8.825"><failure message="pydantic_core._pydantic_core.ValidationError: 1 validation error for Freshness&#10;asof_date&#10;  Value error, Invalid isoformat string: 'api' [type=value_error, input_value='api', input_type=str]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/value_error&#10;During task with name 'run' and id '0ce98a1a-8aeb-33ac-48df-8e121d3a5073'">tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_minister_briefing_endpoin0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0AFF3DD0&gt;

    def test_minister_briefing_endpoint(tmp_path, monkeypatch):
        """Test POST /v1/briefing/minister endpoint returns complete briefing."""
        # Generate synthetic data
        with synthetic_catalog(Path(tmp_path)):
            monkeypatch.setenv("QNWIS_QUERIES_DIR", "src/qnwis/data/queries")
            c = TestClient(app)
&gt;           r = c.post("/v1/briefing/minister")
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\integration\test_api_briefing.py:44: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
.venv\Lib\site-packages\starlette\testclient.py:552: in post
    return super().post(
.venv\Lib\site-packages\httpx\_client.py:1144: in post
    return self.request(
.venv\Lib\site-packages\starlette\testclient.py:451: in request
    return super().request(
.venv\Lib\site-packages\httpx\_client.py:825: in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\httpx\_client.py:914: in send
    response = self._send_handling_auth(
.venv\Lib\site-packages\httpx\_client.py:942: in _send_handling_auth
    response = self._send_handling_redirects(
.venv\Lib\site-packages\httpx\_client.py:979: in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\httpx\_client.py:1014: in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\starlette\testclient.py:354: in handle_request
    raise exc
.venv\Lib\site-packages\starlette\testclient.py:351: in handle_request
    portal.call(self.app, scope, receive, send)
.venv\Lib\site-packages\anyio\from_thread.py:321: in call
    return cast(T_Retval, self.start_task_soon(func, *args).result())
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Program Files\Python311\Lib\concurrent\futures\_base.py:456: in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
C:\Program Files\Python311\Lib\concurrent\futures\_base.py:401: in __get_result
    raise self._exception
.venv\Lib\site-packages\anyio\from_thread.py:252: in _call_func
    retval = await retval_or_awaitable
             ^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\fastapi\applications.py:1134: in __call__
    await super().__call__(scope, receive, send)
.venv\Lib\site-packages\starlette\applications.py:113: in __call__
    await self.middleware_stack(scope, receive, send)
.venv\Lib\site-packages\starlette\middleware\errors.py:186: in __call__
    raise exc
.venv\Lib\site-packages\starlette\middleware\errors.py:164: in __call__
    await self.app(scope, receive, _send)
src\qnwis\utils\request_id.py:75: in __call__
    await self.app(scope, receive, send_wrapper)
.venv\Lib\site-packages\starlette\middleware\exceptions.py:63: in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
.venv\Lib\site-packages\starlette\_exception_handler.py:53: in wrapped_app
    raise exc
.venv\Lib\site-packages\starlette\_exception_handler.py:42: in wrapped_app
    await app(scope, receive, sender)
.venv\Lib\site-packages\fastapi\middleware\asyncexitstack.py:18: in __call__
    await self.app(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:716: in __call__
    await self.middleware_stack(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:736: in app
    await route.handle(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:290: in handle
    await self.app(scope, receive, send)
.venv\Lib\site-packages\fastapi\routing.py:125: in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
.venv\Lib\site-packages\starlette\_exception_handler.py:53: in wrapped_app
    raise exc
.venv\Lib\site-packages\starlette\_exception_handler.py:42: in wrapped_app
    await app(scope, receive, sender)
.venv\Lib\site-packages\fastapi\routing.py:111: in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\fastapi\routing.py:391: in app
    raw_response = await run_endpoint_function(
.venv\Lib\site-packages\fastapi\routing.py:292: in run_endpoint_function
    return await run_in_threadpool(dependant.call, **values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\starlette\concurrency.py:38: in run_in_threadpool
    return await anyio.to_thread.run_sync(func)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\anyio\to_thread.py:56: in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
.venv\Lib\site-packages\anyio\_backends\_asyncio.py:2485: in run_sync_in_worker_thread
    return await future
           ^^^^^^^^^^^^
.venv\Lib\site-packages\anyio\_backends\_asyncio.py:976: in run
    result = context.run(func, *args)
             ^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\api\routers\briefing.py:46: in minister_briefing
    b = build_briefing(queries_dir=queries_dir, ttl_s=effective_ttl)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\briefing\minister.py:96: in build_briefing
    council_json = run_council(CouncilConfig(queries_dir=resolved_queries_dir, ttl_s=ttl_s))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:273: in run_council
    final_state = graph_app.invoke(state)
                  ^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\pregel\main.py:3094: in invoke
    for chunk in self.stream(
.venv\Lib\site-packages\langgraph\pregel\main.py:2679: in stream
    for _ in runner.tick(
.venv\Lib\site-packages\langgraph\pregel\_runner.py:167: in tick
    run_with_retry(
.venv\Lib\site-packages\langgraph\pregel\_retry.py:42: in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\_internal\_runnable.py:656: in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\_internal\_runnable.py:400: in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:182: in run_step
    state["reports"] = _run_agents(state["agents"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:86: in _run_agents
    reports.append(agent.run())
                   ^^^^^^^^^^^
src\qnwis\agents\nationalization.py:42: in run
    res = self.client.run(UNEMPLOY_QUERY)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\agents\base.py:180: in run
    res = execute_cached(query_id, self._registry, ttl_s=self.ttl_s)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\data\deterministic\cache_access.py:222: in execute_cached
    res = execute_uncached(query_id, registry, spec_override=spec)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\data\deterministic\access.py:41: in execute
    result = run_world_bank_query(spec)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

spec = QuerySpec(id='q_unemployment_rate_gcc_latest', title='Unemployment rate GCC comparison', description='Compare Qatar vs...ZS', 'countries': ['QAT', 'SAU', 'ARE', 'KWT', 'BHR', 'OMN']}, expected_unit='percent', constraints={}, postprocess=[])

    def run_world_bank_query(spec: QuerySpec) -&gt; QueryResult:
        """
        Execute a deterministic World Bank query via the shared API integrator.
    
        Required params:
            indicator (str): World Bank indicator code.
    
        Optional params:
            countries (Iterable[str]): ISO-3 country codes (default GCC set).
            year / start_year / end_year: Passed through to the API client.
            timeout_s (float): Maximum seconds per API request (default 30).
            max_rows (int): Maximum rows to include in the result set (default 10000).
        """
        params = spec.params or {}
        indicator = params.get("indicator")
        if not isinstance(indicator, str) or not indicator.strip():
            raise ValueError("World Bank query requires a non-empty 'indicator' parameter.")
        indicator_code = indicator.strip()
    
        countries = _validate_countries(params.get("countries"))
    
        # Default timeout_s to 30 if not provided
        timeout_s = 30.0
        if "timeout_s" in params:
            timeout_s = _validate_positive_number(params["timeout_s"], "timeout_s")
    
        # Default max_rows to 10000 if not provided
        max_rows = 10000
        if "max_rows" in params:
            max_rows = _validate_positive_int(params["max_rows"], "max_rows")
    
        integ = UDCGlobalDataIntegrator()
        dataframe = integ.get_indicator(
            indicator=indicator_code,
            countries=countries,
            year=params.get("year"),
            start_year=params.get("start_year"),
            end_year=params.get("end_year"),
            timeout_s=timeout_s,
            max_rows=max_rows,
        )
    
        if dataframe.empty:
            raise ValueError(
                f"World Bank query returned no data for indicator '{indicator_code}' "
                f"with countries {countries}"
            )
    
        records = dataframe.to_dict(orient="records")
        rows: list[Row] = [Row(data=record) for record in records]
    
        return QueryResult(
            query_id=spec.id,
            rows=rows,
            unit=spec.expected_unit,
            provenance=Provenance(
                source="world_bank",
                dataset_id=indicator_code,
                locator=f"indicator={indicator_code}",
                fields=list(dataframe.columns),
                license=WORLD_BANK_LICENSE,
            ),
&gt;           freshness=Freshness(asof_date="api", updated_at=None),
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       pydantic_core._pydantic_core.ValidationError: 1 validation error for Freshness
E       asof_date
E         Value error, Invalid isoformat string: 'api' [type=value_error, input_value='api', input_type=str]
E           For further information visit https://errors.pydantic.dev/2.12/v/value_error
E       During task with name 'run' and id '0ce98a1a-8aeb-33ac-48df-8e121d3a5073'

src\qnwis\data\connectors\world_bank_det.py:112: ValidationError</failure></testcase><testcase classname="tests.integration.test_api_briefing" name="test_minister_briefing_response_structure" time="7.004"><failure message="pydantic_core._pydantic_core.ValidationError: 1 validation error for Freshness&#10;asof_date&#10;  Value error, Invalid isoformat string: 'api' [type=value_error, input_value='api', input_type=str]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/value_error&#10;During task with name 'run' and id '7c681246-45ba-44e3-6b68-ec49fb6c7e00'">tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_minister_briefing_respons0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0CB83E10&gt;

    def test_minister_briefing_response_structure(tmp_path, monkeypatch):
        """Test that briefing response has all required fields."""
        with synthetic_catalog(Path(tmp_path)):
            monkeypatch.setenv("QNWIS_QUERIES_DIR", "src/qnwis/data/queries")
            c = TestClient(app)
&gt;           r = c.post("/v1/briefing/minister")
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\integration\test_api_briefing.py:56: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
.venv\Lib\site-packages\starlette\testclient.py:552: in post
    return super().post(
.venv\Lib\site-packages\httpx\_client.py:1144: in post
    return self.request(
.venv\Lib\site-packages\starlette\testclient.py:451: in request
    return super().request(
.venv\Lib\site-packages\httpx\_client.py:825: in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\httpx\_client.py:914: in send
    response = self._send_handling_auth(
.venv\Lib\site-packages\httpx\_client.py:942: in _send_handling_auth
    response = self._send_handling_redirects(
.venv\Lib\site-packages\httpx\_client.py:979: in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\httpx\_client.py:1014: in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\starlette\testclient.py:354: in handle_request
    raise exc
.venv\Lib\site-packages\starlette\testclient.py:351: in handle_request
    portal.call(self.app, scope, receive, send)
.venv\Lib\site-packages\anyio\from_thread.py:321: in call
    return cast(T_Retval, self.start_task_soon(func, *args).result())
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Program Files\Python311\Lib\concurrent\futures\_base.py:456: in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
C:\Program Files\Python311\Lib\concurrent\futures\_base.py:401: in __get_result
    raise self._exception
.venv\Lib\site-packages\anyio\from_thread.py:252: in _call_func
    retval = await retval_or_awaitable
             ^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\fastapi\applications.py:1134: in __call__
    await super().__call__(scope, receive, send)
.venv\Lib\site-packages\starlette\applications.py:113: in __call__
    await self.middleware_stack(scope, receive, send)
.venv\Lib\site-packages\starlette\middleware\errors.py:186: in __call__
    raise exc
.venv\Lib\site-packages\starlette\middleware\errors.py:164: in __call__
    await self.app(scope, receive, _send)
src\qnwis\utils\request_id.py:75: in __call__
    await self.app(scope, receive, send_wrapper)
.venv\Lib\site-packages\starlette\middleware\exceptions.py:63: in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
.venv\Lib\site-packages\starlette\_exception_handler.py:53: in wrapped_app
    raise exc
.venv\Lib\site-packages\starlette\_exception_handler.py:42: in wrapped_app
    await app(scope, receive, sender)
.venv\Lib\site-packages\fastapi\middleware\asyncexitstack.py:18: in __call__
    await self.app(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:716: in __call__
    await self.middleware_stack(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:736: in app
    await route.handle(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:290: in handle
    await self.app(scope, receive, send)
.venv\Lib\site-packages\fastapi\routing.py:125: in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
.venv\Lib\site-packages\starlette\_exception_handler.py:53: in wrapped_app
    raise exc
.venv\Lib\site-packages\starlette\_exception_handler.py:42: in wrapped_app
    await app(scope, receive, sender)
.venv\Lib\site-packages\fastapi\routing.py:111: in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\fastapi\routing.py:391: in app
    raw_response = await run_endpoint_function(
.venv\Lib\site-packages\fastapi\routing.py:292: in run_endpoint_function
    return await run_in_threadpool(dependant.call, **values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\starlette\concurrency.py:38: in run_in_threadpool
    return await anyio.to_thread.run_sync(func)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\anyio\to_thread.py:56: in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
.venv\Lib\site-packages\anyio\_backends\_asyncio.py:2485: in run_sync_in_worker_thread
    return await future
           ^^^^^^^^^^^^
.venv\Lib\site-packages\anyio\_backends\_asyncio.py:976: in run
    result = context.run(func, *args)
             ^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\api\routers\briefing.py:46: in minister_briefing
    b = build_briefing(queries_dir=queries_dir, ttl_s=effective_ttl)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\briefing\minister.py:96: in build_briefing
    council_json = run_council(CouncilConfig(queries_dir=resolved_queries_dir, ttl_s=ttl_s))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:273: in run_council
    final_state = graph_app.invoke(state)
                  ^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\pregel\main.py:3094: in invoke
    for chunk in self.stream(
.venv\Lib\site-packages\langgraph\pregel\main.py:2679: in stream
    for _ in runner.tick(
.venv\Lib\site-packages\langgraph\pregel\_runner.py:167: in tick
    run_with_retry(
.venv\Lib\site-packages\langgraph\pregel\_retry.py:42: in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\_internal\_runnable.py:656: in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\_internal\_runnable.py:400: in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:182: in run_step
    state["reports"] = _run_agents(state["agents"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:86: in _run_agents
    reports.append(agent.run())
                   ^^^^^^^^^^^
src\qnwis\agents\nationalization.py:42: in run
    res = self.client.run(UNEMPLOY_QUERY)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\agents\base.py:180: in run
    res = execute_cached(query_id, self._registry, ttl_s=self.ttl_s)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\data\deterministic\cache_access.py:222: in execute_cached
    res = execute_uncached(query_id, registry, spec_override=spec)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\data\deterministic\access.py:41: in execute
    result = run_world_bank_query(spec)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

spec = QuerySpec(id='q_unemployment_rate_gcc_latest', title='Unemployment rate GCC comparison', description='Compare Qatar vs...ZS', 'countries': ['QAT', 'SAU', 'ARE', 'KWT', 'BHR', 'OMN']}, expected_unit='percent', constraints={}, postprocess=[])

    def run_world_bank_query(spec: QuerySpec) -&gt; QueryResult:
        """
        Execute a deterministic World Bank query via the shared API integrator.
    
        Required params:
            indicator (str): World Bank indicator code.
    
        Optional params:
            countries (Iterable[str]): ISO-3 country codes (default GCC set).
            year / start_year / end_year: Passed through to the API client.
            timeout_s (float): Maximum seconds per API request (default 30).
            max_rows (int): Maximum rows to include in the result set (default 10000).
        """
        params = spec.params or {}
        indicator = params.get("indicator")
        if not isinstance(indicator, str) or not indicator.strip():
            raise ValueError("World Bank query requires a non-empty 'indicator' parameter.")
        indicator_code = indicator.strip()
    
        countries = _validate_countries(params.get("countries"))
    
        # Default timeout_s to 30 if not provided
        timeout_s = 30.0
        if "timeout_s" in params:
            timeout_s = _validate_positive_number(params["timeout_s"], "timeout_s")
    
        # Default max_rows to 10000 if not provided
        max_rows = 10000
        if "max_rows" in params:
            max_rows = _validate_positive_int(params["max_rows"], "max_rows")
    
        integ = UDCGlobalDataIntegrator()
        dataframe = integ.get_indicator(
            indicator=indicator_code,
            countries=countries,
            year=params.get("year"),
            start_year=params.get("start_year"),
            end_year=params.get("end_year"),
            timeout_s=timeout_s,
            max_rows=max_rows,
        )
    
        if dataframe.empty:
            raise ValueError(
                f"World Bank query returned no data for indicator '{indicator_code}' "
                f"with countries {countries}"
            )
    
        records = dataframe.to_dict(orient="records")
        rows: list[Row] = [Row(data=record) for record in records]
    
        return QueryResult(
            query_id=spec.id,
            rows=rows,
            unit=spec.expected_unit,
            provenance=Provenance(
                source="world_bank",
                dataset_id=indicator_code,
                locator=f"indicator={indicator_code}",
                fields=list(dataframe.columns),
                license=WORLD_BANK_LICENSE,
            ),
&gt;           freshness=Freshness(asof_date="api", updated_at=None),
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       pydantic_core._pydantic_core.ValidationError: 1 validation error for Freshness
E       asof_date
E         Value error, Invalid isoformat string: 'api' [type=value_error, input_value='api', input_type=str]
E           For further information visit https://errors.pydantic.dev/2.12/v/value_error
E       During task with name 'run' and id '7c681246-45ba-44e3-6b68-ec49fb6c7e00'

src\qnwis\data\connectors\world_bank_det.py:112: ValidationError</failure></testcase><testcase classname="tests.integration.test_api_briefing" name="test_minister_briefing_with_custom_ttl" time="6.963"><failure message="pydantic_core._pydantic_core.ValidationError: 1 validation error for Freshness&#10;asof_date&#10;  Value error, Invalid isoformat string: 'api' [type=value_error, input_value='api', input_type=str]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/value_error&#10;During task with name 'run' and id '85c98c50-2b2c-4646-5399-1e8b9ff04719'">tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_minister_briefing_with_cu0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0C81BA10&gt;

    def test_minister_briefing_with_custom_ttl(tmp_path, monkeypatch):
        """Test that briefing endpoint accepts custom TTL parameter."""
        with synthetic_catalog(Path(tmp_path)):
            monkeypatch.setenv("QNWIS_QUERIES_DIR", "src/qnwis/data/queries")
            c = TestClient(app)
&gt;           r = c.post("/v1/briefing/minister?ttl_s=60")
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\integration\test_api_briefing.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
.venv\Lib\site-packages\starlette\testclient.py:552: in post
    return super().post(
.venv\Lib\site-packages\httpx\_client.py:1144: in post
    return self.request(
.venv\Lib\site-packages\starlette\testclient.py:451: in request
    return super().request(
.venv\Lib\site-packages\httpx\_client.py:825: in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\httpx\_client.py:914: in send
    response = self._send_handling_auth(
.venv\Lib\site-packages\httpx\_client.py:942: in _send_handling_auth
    response = self._send_handling_redirects(
.venv\Lib\site-packages\httpx\_client.py:979: in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\httpx\_client.py:1014: in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\starlette\testclient.py:354: in handle_request
    raise exc
.venv\Lib\site-packages\starlette\testclient.py:351: in handle_request
    portal.call(self.app, scope, receive, send)
.venv\Lib\site-packages\anyio\from_thread.py:321: in call
    return cast(T_Retval, self.start_task_soon(func, *args).result())
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Program Files\Python311\Lib\concurrent\futures\_base.py:456: in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
C:\Program Files\Python311\Lib\concurrent\futures\_base.py:401: in __get_result
    raise self._exception
.venv\Lib\site-packages\anyio\from_thread.py:252: in _call_func
    retval = await retval_or_awaitable
             ^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\fastapi\applications.py:1134: in __call__
    await super().__call__(scope, receive, send)
.venv\Lib\site-packages\starlette\applications.py:113: in __call__
    await self.middleware_stack(scope, receive, send)
.venv\Lib\site-packages\starlette\middleware\errors.py:186: in __call__
    raise exc
.venv\Lib\site-packages\starlette\middleware\errors.py:164: in __call__
    await self.app(scope, receive, _send)
src\qnwis\utils\request_id.py:75: in __call__
    await self.app(scope, receive, send_wrapper)
.venv\Lib\site-packages\starlette\middleware\exceptions.py:63: in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
.venv\Lib\site-packages\starlette\_exception_handler.py:53: in wrapped_app
    raise exc
.venv\Lib\site-packages\starlette\_exception_handler.py:42: in wrapped_app
    await app(scope, receive, sender)
.venv\Lib\site-packages\fastapi\middleware\asyncexitstack.py:18: in __call__
    await self.app(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:716: in __call__
    await self.middleware_stack(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:736: in app
    await route.handle(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:290: in handle
    await self.app(scope, receive, send)
.venv\Lib\site-packages\fastapi\routing.py:125: in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
.venv\Lib\site-packages\starlette\_exception_handler.py:53: in wrapped_app
    raise exc
.venv\Lib\site-packages\starlette\_exception_handler.py:42: in wrapped_app
    await app(scope, receive, sender)
.venv\Lib\site-packages\fastapi\routing.py:111: in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\fastapi\routing.py:391: in app
    raw_response = await run_endpoint_function(
.venv\Lib\site-packages\fastapi\routing.py:292: in run_endpoint_function
    return await run_in_threadpool(dependant.call, **values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\starlette\concurrency.py:38: in run_in_threadpool
    return await anyio.to_thread.run_sync(func)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\anyio\to_thread.py:56: in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
.venv\Lib\site-packages\anyio\_backends\_asyncio.py:2485: in run_sync_in_worker_thread
    return await future
           ^^^^^^^^^^^^
.venv\Lib\site-packages\anyio\_backends\_asyncio.py:976: in run
    result = context.run(func, *args)
             ^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\api\routers\briefing.py:46: in minister_briefing
    b = build_briefing(queries_dir=queries_dir, ttl_s=effective_ttl)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\briefing\minister.py:96: in build_briefing
    council_json = run_council(CouncilConfig(queries_dir=resolved_queries_dir, ttl_s=ttl_s))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:273: in run_council
    final_state = graph_app.invoke(state)
                  ^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\pregel\main.py:3094: in invoke
    for chunk in self.stream(
.venv\Lib\site-packages\langgraph\pregel\main.py:2679: in stream
    for _ in runner.tick(
.venv\Lib\site-packages\langgraph\pregel\_runner.py:167: in tick
    run_with_retry(
.venv\Lib\site-packages\langgraph\pregel\_retry.py:42: in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\_internal\_runnable.py:656: in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\_internal\_runnable.py:400: in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:182: in run_step
    state["reports"] = _run_agents(state["agents"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:86: in _run_agents
    reports.append(agent.run())
                   ^^^^^^^^^^^
src\qnwis\agents\nationalization.py:42: in run
    res = self.client.run(UNEMPLOY_QUERY)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\agents\base.py:180: in run
    res = execute_cached(query_id, self._registry, ttl_s=self.ttl_s)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\data\deterministic\cache_access.py:222: in execute_cached
    res = execute_uncached(query_id, registry, spec_override=spec)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\data\deterministic\access.py:41: in execute
    result = run_world_bank_query(spec)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

spec = QuerySpec(id='q_unemployment_rate_gcc_latest', title='Unemployment rate GCC comparison', description='Compare Qatar vs...ZS', 'countries': ['QAT', 'SAU', 'ARE', 'KWT', 'BHR', 'OMN']}, expected_unit='percent', constraints={}, postprocess=[])

    def run_world_bank_query(spec: QuerySpec) -&gt; QueryResult:
        """
        Execute a deterministic World Bank query via the shared API integrator.
    
        Required params:
            indicator (str): World Bank indicator code.
    
        Optional params:
            countries (Iterable[str]): ISO-3 country codes (default GCC set).
            year / start_year / end_year: Passed through to the API client.
            timeout_s (float): Maximum seconds per API request (default 30).
            max_rows (int): Maximum rows to include in the result set (default 10000).
        """
        params = spec.params or {}
        indicator = params.get("indicator")
        if not isinstance(indicator, str) or not indicator.strip():
            raise ValueError("World Bank query requires a non-empty 'indicator' parameter.")
        indicator_code = indicator.strip()
    
        countries = _validate_countries(params.get("countries"))
    
        # Default timeout_s to 30 if not provided
        timeout_s = 30.0
        if "timeout_s" in params:
            timeout_s = _validate_positive_number(params["timeout_s"], "timeout_s")
    
        # Default max_rows to 10000 if not provided
        max_rows = 10000
        if "max_rows" in params:
            max_rows = _validate_positive_int(params["max_rows"], "max_rows")
    
        integ = UDCGlobalDataIntegrator()
        dataframe = integ.get_indicator(
            indicator=indicator_code,
            countries=countries,
            year=params.get("year"),
            start_year=params.get("start_year"),
            end_year=params.get("end_year"),
            timeout_s=timeout_s,
            max_rows=max_rows,
        )
    
        if dataframe.empty:
            raise ValueError(
                f"World Bank query returned no data for indicator '{indicator_code}' "
                f"with countries {countries}"
            )
    
        records = dataframe.to_dict(orient="records")
        rows: list[Row] = [Row(data=record) for record in records]
    
        return QueryResult(
            query_id=spec.id,
            rows=rows,
            unit=spec.expected_unit,
            provenance=Provenance(
                source="world_bank",
                dataset_id=indicator_code,
                locator=f"indicator={indicator_code}",
                fields=list(dataframe.columns),
                license=WORLD_BANK_LICENSE,
            ),
&gt;           freshness=Freshness(asof_date="api", updated_at=None),
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       pydantic_core._pydantic_core.ValidationError: 1 validation error for Freshness
E       asof_date
E         Value error, Invalid isoformat string: 'api' [type=value_error, input_value='api', input_type=str]
E           For further information visit https://errors.pydantic.dev/2.12/v/value_error
E       During task with name 'run' and id '85c98c50-2b2c-4646-5399-1e8b9ff04719'

src\qnwis\data\connectors\world_bank_det.py:112: ValidationError</failure></testcase><testcase classname="tests.integration.test_api_briefing" name="test_minister_briefing_markdown_content" time="6.943"><failure message="pydantic_core._pydantic_core.ValidationError: 1 validation error for Freshness&#10;asof_date&#10;  Value error, Invalid isoformat string: 'api' [type=value_error, input_value='api', input_type=str]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/value_error&#10;During task with name 'run' and id '457756c1-4451-392a-28cc-5a5254187f8e'">tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_minister_briefing_markdow0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0C067910&gt;

    def test_minister_briefing_markdown_content(tmp_path, monkeypatch):
        """Test that markdown contains expected content structure."""
        with synthetic_catalog(Path(tmp_path)):
            monkeypatch.setenv("QNWIS_QUERIES_DIR", "src/qnwis/data/queries")
            c = TestClient(app)
&gt;           r = c.post("/v1/briefing/minister")
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\integration\test_api_briefing.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
.venv\Lib\site-packages\starlette\testclient.py:552: in post
    return super().post(
.venv\Lib\site-packages\httpx\_client.py:1144: in post
    return self.request(
.venv\Lib\site-packages\starlette\testclient.py:451: in request
    return super().request(
.venv\Lib\site-packages\httpx\_client.py:825: in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\httpx\_client.py:914: in send
    response = self._send_handling_auth(
.venv\Lib\site-packages\httpx\_client.py:942: in _send_handling_auth
    response = self._send_handling_redirects(
.venv\Lib\site-packages\httpx\_client.py:979: in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\httpx\_client.py:1014: in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\starlette\testclient.py:354: in handle_request
    raise exc
.venv\Lib\site-packages\starlette\testclient.py:351: in handle_request
    portal.call(self.app, scope, receive, send)
.venv\Lib\site-packages\anyio\from_thread.py:321: in call
    return cast(T_Retval, self.start_task_soon(func, *args).result())
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Program Files\Python311\Lib\concurrent\futures\_base.py:456: in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
C:\Program Files\Python311\Lib\concurrent\futures\_base.py:401: in __get_result
    raise self._exception
.venv\Lib\site-packages\anyio\from_thread.py:252: in _call_func
    retval = await retval_or_awaitable
             ^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\fastapi\applications.py:1134: in __call__
    await super().__call__(scope, receive, send)
.venv\Lib\site-packages\starlette\applications.py:113: in __call__
    await self.middleware_stack(scope, receive, send)
.venv\Lib\site-packages\starlette\middleware\errors.py:186: in __call__
    raise exc
.venv\Lib\site-packages\starlette\middleware\errors.py:164: in __call__
    await self.app(scope, receive, _send)
src\qnwis\utils\request_id.py:75: in __call__
    await self.app(scope, receive, send_wrapper)
.venv\Lib\site-packages\starlette\middleware\exceptions.py:63: in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
.venv\Lib\site-packages\starlette\_exception_handler.py:53: in wrapped_app
    raise exc
.venv\Lib\site-packages\starlette\_exception_handler.py:42: in wrapped_app
    await app(scope, receive, sender)
.venv\Lib\site-packages\fastapi\middleware\asyncexitstack.py:18: in __call__
    await self.app(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:716: in __call__
    await self.middleware_stack(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:736: in app
    await route.handle(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:290: in handle
    await self.app(scope, receive, send)
.venv\Lib\site-packages\fastapi\routing.py:125: in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
.venv\Lib\site-packages\starlette\_exception_handler.py:53: in wrapped_app
    raise exc
.venv\Lib\site-packages\starlette\_exception_handler.py:42: in wrapped_app
    await app(scope, receive, sender)
.venv\Lib\site-packages\fastapi\routing.py:111: in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\fastapi\routing.py:391: in app
    raw_response = await run_endpoint_function(
.venv\Lib\site-packages\fastapi\routing.py:292: in run_endpoint_function
    return await run_in_threadpool(dependant.call, **values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\starlette\concurrency.py:38: in run_in_threadpool
    return await anyio.to_thread.run_sync(func)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\anyio\to_thread.py:56: in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
.venv\Lib\site-packages\anyio\_backends\_asyncio.py:2485: in run_sync_in_worker_thread
    return await future
           ^^^^^^^^^^^^
.venv\Lib\site-packages\anyio\_backends\_asyncio.py:976: in run
    result = context.run(func, *args)
             ^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\api\routers\briefing.py:46: in minister_briefing
    b = build_briefing(queries_dir=queries_dir, ttl_s=effective_ttl)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\briefing\minister.py:96: in build_briefing
    council_json = run_council(CouncilConfig(queries_dir=resolved_queries_dir, ttl_s=ttl_s))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:273: in run_council
    final_state = graph_app.invoke(state)
                  ^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\pregel\main.py:3094: in invoke
    for chunk in self.stream(
.venv\Lib\site-packages\langgraph\pregel\main.py:2679: in stream
    for _ in runner.tick(
.venv\Lib\site-packages\langgraph\pregel\_runner.py:167: in tick
    run_with_retry(
.venv\Lib\site-packages\langgraph\pregel\_retry.py:42: in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\_internal\_runnable.py:656: in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\_internal\_runnable.py:400: in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:182: in run_step
    state["reports"] = _run_agents(state["agents"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:86: in _run_agents
    reports.append(agent.run())
                   ^^^^^^^^^^^
src\qnwis\agents\nationalization.py:42: in run
    res = self.client.run(UNEMPLOY_QUERY)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\agents\base.py:180: in run
    res = execute_cached(query_id, self._registry, ttl_s=self.ttl_s)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\data\deterministic\cache_access.py:222: in execute_cached
    res = execute_uncached(query_id, registry, spec_override=spec)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\data\deterministic\access.py:41: in execute
    result = run_world_bank_query(spec)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

spec = QuerySpec(id='q_unemployment_rate_gcc_latest', title='Unemployment rate GCC comparison', description='Compare Qatar vs...ZS', 'countries': ['QAT', 'SAU', 'ARE', 'KWT', 'BHR', 'OMN']}, expected_unit='percent', constraints={}, postprocess=[])

    def run_world_bank_query(spec: QuerySpec) -&gt; QueryResult:
        """
        Execute a deterministic World Bank query via the shared API integrator.
    
        Required params:
            indicator (str): World Bank indicator code.
    
        Optional params:
            countries (Iterable[str]): ISO-3 country codes (default GCC set).
            year / start_year / end_year: Passed through to the API client.
            timeout_s (float): Maximum seconds per API request (default 30).
            max_rows (int): Maximum rows to include in the result set (default 10000).
        """
        params = spec.params or {}
        indicator = params.get("indicator")
        if not isinstance(indicator, str) or not indicator.strip():
            raise ValueError("World Bank query requires a non-empty 'indicator' parameter.")
        indicator_code = indicator.strip()
    
        countries = _validate_countries(params.get("countries"))
    
        # Default timeout_s to 30 if not provided
        timeout_s = 30.0
        if "timeout_s" in params:
            timeout_s = _validate_positive_number(params["timeout_s"], "timeout_s")
    
        # Default max_rows to 10000 if not provided
        max_rows = 10000
        if "max_rows" in params:
            max_rows = _validate_positive_int(params["max_rows"], "max_rows")
    
        integ = UDCGlobalDataIntegrator()
        dataframe = integ.get_indicator(
            indicator=indicator_code,
            countries=countries,
            year=params.get("year"),
            start_year=params.get("start_year"),
            end_year=params.get("end_year"),
            timeout_s=timeout_s,
            max_rows=max_rows,
        )
    
        if dataframe.empty:
            raise ValueError(
                f"World Bank query returned no data for indicator '{indicator_code}' "
                f"with countries {countries}"
            )
    
        records = dataframe.to_dict(orient="records")
        rows: list[Row] = [Row(data=record) for record in records]
    
        return QueryResult(
            query_id=spec.id,
            rows=rows,
            unit=spec.expected_unit,
            provenance=Provenance(
                source="world_bank",
                dataset_id=indicator_code,
                locator=f"indicator={indicator_code}",
                fields=list(dataframe.columns),
                license=WORLD_BANK_LICENSE,
            ),
&gt;           freshness=Freshness(asof_date="api", updated_at=None),
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       pydantic_core._pydantic_core.ValidationError: 1 validation error for Freshness
E       asof_date
E         Value error, Invalid isoformat string: 'api' [type=value_error, input_value='api', input_type=str]
E           For further information visit https://errors.pydantic.dev/2.12/v/value_error
E       During task with name 'run' and id '457756c1-4451-392a-28cc-5a5254187f8e'

src\qnwis\data\connectors\world_bank_det.py:112: ValidationError</failure></testcase><testcase classname="tests.integration.test_api_briefing" name="test_minister_briefing_key_metrics_numeric" time="6.964"><failure message="pydantic_core._pydantic_core.ValidationError: 1 validation error for Freshness&#10;asof_date&#10;  Value error, Invalid isoformat string: 'api' [type=value_error, input_value='api', input_type=str]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/value_error&#10;During task with name 'run' and id '3405ef30-a7a5-5245-d88c-28ad72e40365'">tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_minister_briefing_key_met0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0BFDEC10&gt;

    def test_minister_briefing_key_metrics_numeric(tmp_path, monkeypatch):
        """Test that key_metrics contains only numeric values."""
        with synthetic_catalog(Path(tmp_path)):
            monkeypatch.setenv("QNWIS_QUERIES_DIR", "src/qnwis/data/queries")
            c = TestClient(app)
&gt;           r = c.post("/v1/briefing/minister")
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\integration\test_api_briefing.py:116: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
.venv\Lib\site-packages\starlette\testclient.py:552: in post
    return super().post(
.venv\Lib\site-packages\httpx\_client.py:1144: in post
    return self.request(
.venv\Lib\site-packages\starlette\testclient.py:451: in request
    return super().request(
.venv\Lib\site-packages\httpx\_client.py:825: in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\httpx\_client.py:914: in send
    response = self._send_handling_auth(
.venv\Lib\site-packages\httpx\_client.py:942: in _send_handling_auth
    response = self._send_handling_redirects(
.venv\Lib\site-packages\httpx\_client.py:979: in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\httpx\_client.py:1014: in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\starlette\testclient.py:354: in handle_request
    raise exc
.venv\Lib\site-packages\starlette\testclient.py:351: in handle_request
    portal.call(self.app, scope, receive, send)
.venv\Lib\site-packages\anyio\from_thread.py:321: in call
    return cast(T_Retval, self.start_task_soon(func, *args).result())
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Program Files\Python311\Lib\concurrent\futures\_base.py:456: in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
C:\Program Files\Python311\Lib\concurrent\futures\_base.py:401: in __get_result
    raise self._exception
.venv\Lib\site-packages\anyio\from_thread.py:252: in _call_func
    retval = await retval_or_awaitable
             ^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\fastapi\applications.py:1134: in __call__
    await super().__call__(scope, receive, send)
.venv\Lib\site-packages\starlette\applications.py:113: in __call__
    await self.middleware_stack(scope, receive, send)
.venv\Lib\site-packages\starlette\middleware\errors.py:186: in __call__
    raise exc
.venv\Lib\site-packages\starlette\middleware\errors.py:164: in __call__
    await self.app(scope, receive, _send)
src\qnwis\utils\request_id.py:75: in __call__
    await self.app(scope, receive, send_wrapper)
.venv\Lib\site-packages\starlette\middleware\exceptions.py:63: in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
.venv\Lib\site-packages\starlette\_exception_handler.py:53: in wrapped_app
    raise exc
.venv\Lib\site-packages\starlette\_exception_handler.py:42: in wrapped_app
    await app(scope, receive, sender)
.venv\Lib\site-packages\fastapi\middleware\asyncexitstack.py:18: in __call__
    await self.app(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:716: in __call__
    await self.middleware_stack(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:736: in app
    await route.handle(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:290: in handle
    await self.app(scope, receive, send)
.venv\Lib\site-packages\fastapi\routing.py:125: in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
.venv\Lib\site-packages\starlette\_exception_handler.py:53: in wrapped_app
    raise exc
.venv\Lib\site-packages\starlette\_exception_handler.py:42: in wrapped_app
    await app(scope, receive, sender)
.venv\Lib\site-packages\fastapi\routing.py:111: in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\fastapi\routing.py:391: in app
    raw_response = await run_endpoint_function(
.venv\Lib\site-packages\fastapi\routing.py:292: in run_endpoint_function
    return await run_in_threadpool(dependant.call, **values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\starlette\concurrency.py:38: in run_in_threadpool
    return await anyio.to_thread.run_sync(func)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\anyio\to_thread.py:56: in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
.venv\Lib\site-packages\anyio\_backends\_asyncio.py:2485: in run_sync_in_worker_thread
    return await future
           ^^^^^^^^^^^^
.venv\Lib\site-packages\anyio\_backends\_asyncio.py:976: in run
    result = context.run(func, *args)
             ^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\api\routers\briefing.py:46: in minister_briefing
    b = build_briefing(queries_dir=queries_dir, ttl_s=effective_ttl)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\briefing\minister.py:96: in build_briefing
    council_json = run_council(CouncilConfig(queries_dir=resolved_queries_dir, ttl_s=ttl_s))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:273: in run_council
    final_state = graph_app.invoke(state)
                  ^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\pregel\main.py:3094: in invoke
    for chunk in self.stream(
.venv\Lib\site-packages\langgraph\pregel\main.py:2679: in stream
    for _ in runner.tick(
.venv\Lib\site-packages\langgraph\pregel\_runner.py:167: in tick
    run_with_retry(
.venv\Lib\site-packages\langgraph\pregel\_retry.py:42: in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\_internal\_runnable.py:656: in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\_internal\_runnable.py:400: in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:182: in run_step
    state["reports"] = _run_agents(state["agents"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:86: in _run_agents
    reports.append(agent.run())
                   ^^^^^^^^^^^
src\qnwis\agents\nationalization.py:42: in run
    res = self.client.run(UNEMPLOY_QUERY)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\agents\base.py:180: in run
    res = execute_cached(query_id, self._registry, ttl_s=self.ttl_s)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\data\deterministic\cache_access.py:222: in execute_cached
    res = execute_uncached(query_id, registry, spec_override=spec)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\data\deterministic\access.py:41: in execute
    result = run_world_bank_query(spec)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

spec = QuerySpec(id='q_unemployment_rate_gcc_latest', title='Unemployment rate GCC comparison', description='Compare Qatar vs...ZS', 'countries': ['QAT', 'SAU', 'ARE', 'KWT', 'BHR', 'OMN']}, expected_unit='percent', constraints={}, postprocess=[])

    def run_world_bank_query(spec: QuerySpec) -&gt; QueryResult:
        """
        Execute a deterministic World Bank query via the shared API integrator.
    
        Required params:
            indicator (str): World Bank indicator code.
    
        Optional params:
            countries (Iterable[str]): ISO-3 country codes (default GCC set).
            year / start_year / end_year: Passed through to the API client.
            timeout_s (float): Maximum seconds per API request (default 30).
            max_rows (int): Maximum rows to include in the result set (default 10000).
        """
        params = spec.params or {}
        indicator = params.get("indicator")
        if not isinstance(indicator, str) or not indicator.strip():
            raise ValueError("World Bank query requires a non-empty 'indicator' parameter.")
        indicator_code = indicator.strip()
    
        countries = _validate_countries(params.get("countries"))
    
        # Default timeout_s to 30 if not provided
        timeout_s = 30.0
        if "timeout_s" in params:
            timeout_s = _validate_positive_number(params["timeout_s"], "timeout_s")
    
        # Default max_rows to 10000 if not provided
        max_rows = 10000
        if "max_rows" in params:
            max_rows = _validate_positive_int(params["max_rows"], "max_rows")
    
        integ = UDCGlobalDataIntegrator()
        dataframe = integ.get_indicator(
            indicator=indicator_code,
            countries=countries,
            year=params.get("year"),
            start_year=params.get("start_year"),
            end_year=params.get("end_year"),
            timeout_s=timeout_s,
            max_rows=max_rows,
        )
    
        if dataframe.empty:
            raise ValueError(
                f"World Bank query returned no data for indicator '{indicator_code}' "
                f"with countries {countries}"
            )
    
        records = dataframe.to_dict(orient="records")
        rows: list[Row] = [Row(data=record) for record in records]
    
        return QueryResult(
            query_id=spec.id,
            rows=rows,
            unit=spec.expected_unit,
            provenance=Provenance(
                source="world_bank",
                dataset_id=indicator_code,
                locator=f"indicator={indicator_code}",
                fields=list(dataframe.columns),
                license=WORLD_BANK_LICENSE,
            ),
&gt;           freshness=Freshness(asof_date="api", updated_at=None),
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       pydantic_core._pydantic_core.ValidationError: 1 validation error for Freshness
E       asof_date
E         Value error, Invalid isoformat string: 'api' [type=value_error, input_value='api', input_type=str]
E           For further information visit https://errors.pydantic.dev/2.12/v/value_error
E       During task with name 'run' and id '3405ef30-a7a5-5245-d88c-28ad72e40365'

src\qnwis\data\connectors\world_bank_det.py:112: ValidationError</failure></testcase><testcase classname="tests.integration.test_api_briefing" name="test_minister_briefing_deterministic" time="6.990"><failure message="pydantic_core._pydantic_core.ValidationError: 1 validation error for Freshness&#10;asof_date&#10;  Value error, Invalid isoformat string: 'api' [type=value_error, input_value='api', input_type=str]&#10;    For further information visit https://errors.pydantic.dev/2.12/v/value_error&#10;During task with name 'run' and id '448071df-445d-a7e6-c021-6d3301239c92'">tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_minister_briefing_determi0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0C4A5F10&gt;

    def test_minister_briefing_deterministic(tmp_path, monkeypatch):
        """Test that briefing is deterministic (same data = same result)."""
        with synthetic_catalog(Path(tmp_path)):
            monkeypatch.setenv("QNWIS_QUERIES_DIR", "src/qnwis/data/queries")
            c = TestClient(app)
    
            # Call twice
&gt;           r1 = c.post("/v1/briefing/minister")
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\integration\test_api_briefing.py:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
.venv\Lib\site-packages\starlette\testclient.py:552: in post
    return super().post(
.venv\Lib\site-packages\httpx\_client.py:1144: in post
    return self.request(
.venv\Lib\site-packages\starlette\testclient.py:451: in request
    return super().request(
.venv\Lib\site-packages\httpx\_client.py:825: in request
    return self.send(request, auth=auth, follow_redirects=follow_redirects)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\httpx\_client.py:914: in send
    response = self._send_handling_auth(
.venv\Lib\site-packages\httpx\_client.py:942: in _send_handling_auth
    response = self._send_handling_redirects(
.venv\Lib\site-packages\httpx\_client.py:979: in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\httpx\_client.py:1014: in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\starlette\testclient.py:354: in handle_request
    raise exc
.venv\Lib\site-packages\starlette\testclient.py:351: in handle_request
    portal.call(self.app, scope, receive, send)
.venv\Lib\site-packages\anyio\from_thread.py:321: in call
    return cast(T_Retval, self.start_task_soon(func, *args).result())
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Program Files\Python311\Lib\concurrent\futures\_base.py:456: in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
C:\Program Files\Python311\Lib\concurrent\futures\_base.py:401: in __get_result
    raise self._exception
.venv\Lib\site-packages\anyio\from_thread.py:252: in _call_func
    retval = await retval_or_awaitable
             ^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\fastapi\applications.py:1134: in __call__
    await super().__call__(scope, receive, send)
.venv\Lib\site-packages\starlette\applications.py:113: in __call__
    await self.middleware_stack(scope, receive, send)
.venv\Lib\site-packages\starlette\middleware\errors.py:186: in __call__
    raise exc
.venv\Lib\site-packages\starlette\middleware\errors.py:164: in __call__
    await self.app(scope, receive, _send)
src\qnwis\utils\request_id.py:75: in __call__
    await self.app(scope, receive, send_wrapper)
.venv\Lib\site-packages\starlette\middleware\exceptions.py:63: in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
.venv\Lib\site-packages\starlette\_exception_handler.py:53: in wrapped_app
    raise exc
.venv\Lib\site-packages\starlette\_exception_handler.py:42: in wrapped_app
    await app(scope, receive, sender)
.venv\Lib\site-packages\fastapi\middleware\asyncexitstack.py:18: in __call__
    await self.app(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:716: in __call__
    await self.middleware_stack(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:736: in app
    await route.handle(scope, receive, send)
.venv\Lib\site-packages\starlette\routing.py:290: in handle
    await self.app(scope, receive, send)
.venv\Lib\site-packages\fastapi\routing.py:125: in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
.venv\Lib\site-packages\starlette\_exception_handler.py:53: in wrapped_app
    raise exc
.venv\Lib\site-packages\starlette\_exception_handler.py:42: in wrapped_app
    await app(scope, receive, sender)
.venv\Lib\site-packages\fastapi\routing.py:111: in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\fastapi\routing.py:391: in app
    raw_response = await run_endpoint_function(
.venv\Lib\site-packages\fastapi\routing.py:292: in run_endpoint_function
    return await run_in_threadpool(dependant.call, **values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\starlette\concurrency.py:38: in run_in_threadpool
    return await anyio.to_thread.run_sync(func)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\anyio\to_thread.py:56: in run_sync
    return await get_async_backend().run_sync_in_worker_thread(
.venv\Lib\site-packages\anyio\_backends\_asyncio.py:2485: in run_sync_in_worker_thread
    return await future
           ^^^^^^^^^^^^
.venv\Lib\site-packages\anyio\_backends\_asyncio.py:976: in run
    result = context.run(func, *args)
             ^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\api\routers\briefing.py:46: in minister_briefing
    b = build_briefing(queries_dir=queries_dir, ttl_s=effective_ttl)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\briefing\minister.py:96: in build_briefing
    council_json = run_council(CouncilConfig(queries_dir=resolved_queries_dir, ttl_s=ttl_s))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:273: in run_council
    final_state = graph_app.invoke(state)
                  ^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\pregel\main.py:3094: in invoke
    for chunk in self.stream(
.venv\Lib\site-packages\langgraph\pregel\main.py:2679: in stream
    for _ in runner.tick(
.venv\Lib\site-packages\langgraph\pregel\_runner.py:167: in tick
    run_with_retry(
.venv\Lib\site-packages\langgraph\pregel\_retry.py:42: in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\_internal\_runnable.py:656: in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv\Lib\site-packages\langgraph\_internal\_runnable.py:400: in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:182: in run_step
    state["reports"] = _run_agents(state["agents"])
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\orchestration\council.py:86: in _run_agents
    reports.append(agent.run())
                   ^^^^^^^^^^^
src\qnwis\agents\nationalization.py:42: in run
    res = self.client.run(UNEMPLOY_QUERY)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\agents\base.py:180: in run
    res = execute_cached(query_id, self._registry, ttl_s=self.ttl_s)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\data\deterministic\cache_access.py:222: in execute_cached
    res = execute_uncached(query_id, registry, spec_override=spec)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src\qnwis\data\deterministic\access.py:41: in execute
    result = run_world_bank_query(spec)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

spec = QuerySpec(id='q_unemployment_rate_gcc_latest', title='Unemployment rate GCC comparison', description='Compare Qatar vs...ZS', 'countries': ['QAT', 'SAU', 'ARE', 'KWT', 'BHR', 'OMN']}, expected_unit='percent', constraints={}, postprocess=[])

    def run_world_bank_query(spec: QuerySpec) -&gt; QueryResult:
        """
        Execute a deterministic World Bank query via the shared API integrator.
    
        Required params:
            indicator (str): World Bank indicator code.
    
        Optional params:
            countries (Iterable[str]): ISO-3 country codes (default GCC set).
            year / start_year / end_year: Passed through to the API client.
            timeout_s (float): Maximum seconds per API request (default 30).
            max_rows (int): Maximum rows to include in the result set (default 10000).
        """
        params = spec.params or {}
        indicator = params.get("indicator")
        if not isinstance(indicator, str) or not indicator.strip():
            raise ValueError("World Bank query requires a non-empty 'indicator' parameter.")
        indicator_code = indicator.strip()
    
        countries = _validate_countries(params.get("countries"))
    
        # Default timeout_s to 30 if not provided
        timeout_s = 30.0
        if "timeout_s" in params:
            timeout_s = _validate_positive_number(params["timeout_s"], "timeout_s")
    
        # Default max_rows to 10000 if not provided
        max_rows = 10000
        if "max_rows" in params:
            max_rows = _validate_positive_int(params["max_rows"], "max_rows")
    
        integ = UDCGlobalDataIntegrator()
        dataframe = integ.get_indicator(
            indicator=indicator_code,
            countries=countries,
            year=params.get("year"),
            start_year=params.get("start_year"),
            end_year=params.get("end_year"),
            timeout_s=timeout_s,
            max_rows=max_rows,
        )
    
        if dataframe.empty:
            raise ValueError(
                f"World Bank query returned no data for indicator '{indicator_code}' "
                f"with countries {countries}"
            )
    
        records = dataframe.to_dict(orient="records")
        rows: list[Row] = [Row(data=record) for record in records]
    
        return QueryResult(
            query_id=spec.id,
            rows=rows,
            unit=spec.expected_unit,
            provenance=Provenance(
                source="world_bank",
                dataset_id=indicator_code,
                locator=f"indicator={indicator_code}",
                fields=list(dataframe.columns),
                license=WORLD_BANK_LICENSE,
            ),
&gt;           freshness=Freshness(asof_date="api", updated_at=None),
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        )
E       pydantic_core._pydantic_core.ValidationError: 1 validation error for Freshness
E       asof_date
E         Value error, Invalid isoformat string: 'api' [type=value_error, input_value='api', input_type=str]
E           For further information visit https://errors.pydantic.dev/2.12/v/value_error
E       During task with name 'run' and id '448071df-445d-a7e6-c021-6d3301239c92'

src\qnwis\data\connectors\world_bank_det.py:112: ValidationError</failure></testcase><testcase classname="tests.integration.test_api_briefing" name="test_minister_briefing_ttl_clamped" time="0.013" /><testcase classname="tests.integration.test_api_council" name="test_council_endpoint_exists" time="0.018" /><testcase classname="tests.integration.test_api_council" name="test_council_endpoint_returns_json" time="0.017" /><testcase classname="tests.integration.test_api_council" name="test_council_endpoint_structure" time="0.018" /><testcase classname="tests.integration.test_api_council" name="test_council_endpoint_with_params" time="0.017" /><testcase classname="tests.integration.test_api_council" name="test_council_endpoint_agents_present" time="0.018" /><testcase classname="tests.integration.test_api_council" name="test_council_endpoint_findings_format" time="0.017" /><testcase classname="tests.integration.test_api_council" name="test_council_endpoint_verification_format" time="0.018" /><testcase classname="tests.integration.test_api_council" name="test_council_endpoint_consensus" time="0.018" /><testcase classname="tests.integration.test_api_council" name="test_council_endpoint_warnings" time="0.017" /><testcase classname="tests.integration.test_api_council" name="test_council_endpoint_idempotent" time="0.038" /><testcase classname="tests.integration.test_api_council" name="test_council_endpoint_post_method_only" time="0.014" /><testcase classname="tests.integration.test_api_council" name="test_council_endpoint_with_queries_dir" time="0.020" /><testcase classname="tests.integration.test_api_council" name="test_council_endpoint_tags" time="0.073" /><testcase classname="tests.integration.test_api_queries" name="test_list_queries" time="0.025" /><testcase classname="tests.integration.test_api_queries" name="test_list_queries_empty" time="0.009" /><testcase classname="tests.integration.test_api_queries" name="test_run_query_basic" time="0.033" /><testcase classname="tests.integration.test_api_queries" name="test_run_query_with_ttl" time="0.025" /><testcase classname="tests.integration.test_api_queries" name="test_run_query_with_param_overrides" time="0.022" /><testcase classname="tests.integration.test_api_queries" name="test_run_query_overrides_do_not_mutate_registry" time="0.035" /><testcase classname="tests.integration.test_api_queries" name="test_run_query_ttl_bounds" time="0.055" /><testcase classname="tests.integration.test_api_queries" name="test_run_query_invalid_override_type" time="0.016" /><testcase classname="tests.integration.test_api_queries" name="test_run_query_whitelisted_params" time="0.038" /><testcase classname="tests.integration.test_api_queries" name="test_run_query_unknown_id" time="0.016" /><testcase classname="tests.integration.test_api_queries" name="test_run_query_normalized_rows" time="0.023" /><testcase classname="tests.integration.test_api_queries" name="test_run_query_provenance_and_freshness" time="0.022" /><testcase classname="tests.integration.test_api_queries" name="test_get_query_spec" time="0.016" /><testcase classname="tests.integration.test_api_queries" name="test_get_query_spec_unknown" time="0.016" /><testcase classname="tests.integration.test_api_queries" name="test_run_query_no_sum_to_one_warnings" time="0.024" /><testcase classname="tests.integration.test_api_queries" name="test_invalidate_cache" time="0.032" /><testcase classname="tests.integration.test_api_queries" name="test_invalidate_cache_unknown_query" time="0.017" /><testcase classname="tests.integration.test_api_queries" name="test_request_id_header" time="0.025" /><testcase classname="tests.integration.test_api_queries" name="test_health_endpoints" time="0.009" /><testcase classname="tests.integration.test_api_queries" name="test_queries_dir_fallback" time="0.201" /><testcase classname="tests.integration.test_api_ui_cards" name="test_ui_cards_top_sectors" time="2.322" /><testcase classname="tests.integration.test_api_ui_cards" name="test_ui_cards_ewi" time="2.345" /><testcase classname="tests.integration.test_api_ui_cards" name="test_ui_cards_parameter_validation" time="1.918" /><testcase classname="tests.integration.test_api_ui_charts" name="test_ui_chart_salary_yoy" time="1.915" /><testcase classname="tests.integration.test_api_ui_charts" name="test_ui_chart_sector_employment" time="2.319" /><testcase classname="tests.integration.test_api_ui_charts" name="test_ui_chart_employment_share" time="2.108" /><testcase classname="tests.integration.test_api_ui_charts" name="test_ui_charts_ttl_clamping" time="1.908" /><testcase classname="tests.integration.test_api_ui_dashboard" name="test_dashboard_and_exports" time="3.252" /><testcase classname="tests.integration.test_api_ui_dashboard" name="test_dashboard_with_params" time="1.305"><failure message="OSError: [Errno 28] No space left on device">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_dashboard_with_params0/employment_history.csv')
years = [2017, 2018, 2019, 2020, 2021, 2022, ...], n_companies = 800
n_employees = 20000, r = &lt;random.Random object at 0x000001DB0A00F160&gt;

    def _write_employment_history(
        path: Path,
        years: list[int],
        n_companies: int,
        n_employees: int,
        r: random.Random,
    ) -&gt; None:
        """Emit employment_history.csv with per person-year rows."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(EmploymentHistorySchema().columns)
            for pid in range(1, n_employees + 1):
                gender = _weighted_choice(r, [("Male", 0.71), ("Female", 0.29)])
                nationality = _weighted_choice(r, [("Qatari", 0.14), ("Non-Qatari", 0.86)])
                education = _weighted_choice(
                    r, [(e, 1.0 / (i + 1)) for i, e in enumerate(EDULEVEL)]
                )
                anchor_company = r.randint(1, n_companies)
                base_salary = r.randint(3500, 42000)
                employed = True
                for year in years:
                    if r.random() &lt; EMPLOYEE_REENTRY_PROB:
                        employed = not employed
                    company_id = anchor_company if employed else r.randint(1, n_companies)
                    drift = 1.0 + r.uniform(WAGE_DRIFT_LOW, WAGE_DRIFT_HIGH)
                    base_salary = max(SALARY_FLOOR_QR, int(base_salary * drift))
                    status = "employed" if employed else "exited"
&gt;                   writer.writerow(
                        [
                            pid,
                            year,
                            company_id,
                            gender,
                            nationality,
                            education,
                            base_salary,
                            status,
                        ]
                    )
E                   OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:135: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 135, in _write_employment_history
    writer.writerow(
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_dashboard_with_params0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0BD9E6D0&gt;

    def test_dashboard_with_params(tmp_path: Path, monkeypatch: object) -&gt; None:
        """Test dashboard with custom year and sector parameters."""
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_api_ui_dashboard.py:60: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:306: in generate_synthetic_lmis
    _write_employment_history(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_dashboard_with_params0/employment_history.csv')
years = [2017, 2018, 2019, 2020, 2021, 2022, ...], n_companies = 800
n_employees = 20000, r = &lt;random.Random object at 0x000001DB0A00F160&gt;

    def _write_employment_history(
        path: Path,
        years: list[int],
        n_companies: int,
        n_employees: int,
        r: random.Random,
    ) -&gt; None:
        """Emit employment_history.csv with per person-year rows."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:116: OSError</failure></testcase><testcase classname="tests.integration.test_api_ui_dashboard" name="test_export_etags" time="0.010"><failure message="OSError: [Errno 28] No space left on device">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_export_etags0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09EC0040&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_export_etags0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0B095710&gt;

    def test_export_etags(tmp_path: Path, monkeypatch: object) -&gt; None:
        """Test that exports include ETag headers."""
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_api_ui_dashboard.py:77: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_export_etags0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09EC0040&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</failure></testcase><testcase classname="tests.integration.test_api_ui_dashboard" name="test_dashboard_etag_short_circuit" time="0.010"><failure message="OSError: [Errno 28] No space left on device">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_dashboard_etag_short_circ0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09D70290&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_dashboard_etag_short_circ0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0C18B710&gt;

    def test_dashboard_etag_short_circuit(tmp_path: Path, monkeypatch: object) -&gt; None:
        """Test that dashboard endpoints honour If-None-Match and return 304."""
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_api_ui_dashboard.py:106: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_dashboard_etag_short_circ0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09D70290&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</failure></testcase><testcase classname="tests.integration.test_api_ui_dashboard" name="test_export_deterministic" time="0.010"><failure message="OSError: [Errno 28] No space left on device">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_export_deterministic0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09EC0040&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_export_deterministic0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0CBDC8D0&gt;

    def test_export_deterministic(tmp_path: Path, monkeypatch: object) -&gt; None:
        """Test that exports produce deterministic output."""
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_api_ui_dashboard.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_export_deterministic0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09EC0040&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</failure></testcase><testcase classname="tests.integration.test_api_ui_dashboard" name="test_csv_export_validation" time="0.010"><failure message="OSError: [Errno 28] No space left on device">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_csv_export_validation0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09D3E220&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_csv_export_validation0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0AF44D10&gt;

    def test_csv_export_validation(tmp_path: Path, monkeypatch: object) -&gt; None:
        """Test CSV export parameter validation."""
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_api_ui_dashboard.py:162: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_csv_export_validation0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09D3E220&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</failure></testcase><testcase classname="tests.integration.test_api_ui_dashboard" name="test_png_export_validation" time="0.010"><failure message="OSError: [Errno 28] No space left on device">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_png_export_validation0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09EC0040&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_png_export_validation0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0BA31E50&gt;

    def test_png_export_validation(tmp_path: Path, monkeypatch: object) -&gt; None:
        """Test PNG export parameter validation."""
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_api_ui_dashboard.py:186: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_png_export_validation0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09EC0040&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</failure></testcase><testcase classname="tests.integration.test_api_ui_dashboard" name="test_top_sectors_csv_with_n" time="0.011"><failure message="OSError: [Errno 28] No space left on device">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_top_sectors_csv_with_n0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09D3EC30&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_top_sectors_csv_with_n0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0BBEE350&gt;

    def test_top_sectors_csv_with_n(tmp_path: Path, monkeypatch: object) -&gt; None:
        """Test top sectors CSV with different n values."""
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_api_ui_dashboard.py:210: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_top_sectors_csv_with_n0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09D3EC30&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</failure></testcase><testcase classname="tests.integration.test_api_ui_dashboard" name="test_dashboard_default_year" time="0.010"><failure message="OSError: [Errno 28] No space left on device">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_dashboard_default_year0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09D3F640&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_dashboard_default_year0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0BC01DD0&gt;

    def test_dashboard_default_year(tmp_path: Path, monkeypatch: object) -&gt; None:
        """Test dashboard uses latest year when not specified."""
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_api_ui_dashboard.py:236: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_dashboard_default_year0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09D3F640&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</failure></testcase><testcase classname="tests.integration.test_api_ui_export" name="test_export_csv_top_sectors" time="0.010"><failure message="OSError: [Errno 28] No space left on device">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_export_csv_top_sectors0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09D3EC30&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_export_csv_top_sectors0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0B7E99D0&gt;

    def test_export_csv_top_sectors(tmp_path: Path, monkeypatch: object) -&gt; None:
        """Test CSV export for top sectors resource."""
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_api_ui_export.py:21: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_export_csv_top_sectors0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09D3EC30&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</failure></testcase><testcase classname="tests.integration.test_api_ui_export" name="test_export_csv_ewi" time="0.008"><error message="failed on setup with &quot;OSError: could not create numbered dir with prefix test_export_csv_ewi in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries&quot;">fixturedef = &lt;FixtureDef argname='tmp_path' scope='function' baseid=''&gt;
request = &lt;SubRequest 'tmp_path' for &lt;Function test_export_csv_ewi&gt;&gt;

    @pytest.hookimpl(wrapper=True)
    def pytest_fixture_setup(fixturedef: FixtureDef, request) -&gt; object | None:
        asyncio_mode = _get_asyncio_mode(request.config)
        if not _is_asyncio_fixture_function(fixturedef.func):
            if asyncio_mode == Mode.STRICT:
                # Ignore async fixtures without explicit asyncio mark in strict mode
                # This applies to pytest_trio fixtures, for example
                return (yield)
            if not _is_coroutine_or_asyncgen(fixturedef.func):
&gt;               return (yield)
                        ^^^^^
E               OSError: could not create numbered dir with prefix test_export_csv_ewi in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries

.venv\Lib\site-packages\pytest_asyncio\plugin.py:735: OSError</error></testcase><testcase classname="tests.integration.test_api_ui_export" name="test_export_csv_sector_employment" time="0.008"><error message="failed on setup with &quot;OSError: could not create numbered dir with prefix test_export_csv_sector_employm in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries&quot;">fixturedef = &lt;FixtureDef argname='tmp_path' scope='function' baseid=''&gt;
request = &lt;SubRequest 'tmp_path' for &lt;Function test_export_csv_sector_employment&gt;&gt;

    @pytest.hookimpl(wrapper=True)
    def pytest_fixture_setup(fixturedef: FixtureDef, request) -&gt; object | None:
        asyncio_mode = _get_asyncio_mode(request.config)
        if not _is_asyncio_fixture_function(fixturedef.func):
            if asyncio_mode == Mode.STRICT:
                # Ignore async fixtures without explicit asyncio mark in strict mode
                # This applies to pytest_trio fixtures, for example
                return (yield)
            if not _is_coroutine_or_asyncgen(fixturedef.func):
&gt;               return (yield)
                        ^^^^^
E               OSError: could not create numbered dir with prefix test_export_csv_sector_employm in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries

.venv\Lib\site-packages\pytest_asyncio\plugin.py:735: OSError</error></testcase><testcase classname="tests.integration.test_api_ui_export" name="test_export_csv_salary_yoy" time="0.008"><error message="failed on setup with &quot;OSError: could not create numbered dir with prefix test_export_csv_salary_yoy in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries&quot;">fixturedef = &lt;FixtureDef argname='tmp_path' scope='function' baseid=''&gt;
request = &lt;SubRequest 'tmp_path' for &lt;Function test_export_csv_salary_yoy&gt;&gt;

    @pytest.hookimpl(wrapper=True)
    def pytest_fixture_setup(fixturedef: FixtureDef, request) -&gt; object | None:
        asyncio_mode = _get_asyncio_mode(request.config)
        if not _is_asyncio_fixture_function(fixturedef.func):
            if asyncio_mode == Mode.STRICT:
                # Ignore async fixtures without explicit asyncio mark in strict mode
                # This applies to pytest_trio fixtures, for example
                return (yield)
            if not _is_coroutine_or_asyncgen(fixturedef.func):
&gt;               return (yield)
                        ^^^^^
E               OSError: could not create numbered dir with prefix test_export_csv_salary_yoy in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries

.venv\Lib\site-packages\pytest_asyncio\plugin.py:735: OSError</error></testcase><testcase classname="tests.integration.test_api_ui_export" name="test_export_csv_employment_share" time="0.008"><error message="failed on setup with &quot;OSError: could not create numbered dir with prefix test_export_csv_employment_sha in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries&quot;">fixturedef = &lt;FixtureDef argname='tmp_path' scope='function' baseid=''&gt;
request = &lt;SubRequest 'tmp_path' for &lt;Function test_export_csv_employment_share&gt;&gt;

    @pytest.hookimpl(wrapper=True)
    def pytest_fixture_setup(fixturedef: FixtureDef, request) -&gt; object | None:
        asyncio_mode = _get_asyncio_mode(request.config)
        if not _is_asyncio_fixture_function(fixturedef.func):
            if asyncio_mode == Mode.STRICT:
                # Ignore async fixtures without explicit asyncio mark in strict mode
                # This applies to pytest_trio fixtures, for example
                return (yield)
            if not _is_coroutine_or_asyncgen(fixturedef.func):
&gt;               return (yield)
                        ^^^^^
E               OSError: could not create numbered dir with prefix test_export_csv_employment_sha in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries

.venv\Lib\site-packages\pytest_asyncio\plugin.py:735: OSError</error></testcase><testcase classname="tests.integration.test_api_ui_export" name="test_export_csv_etag_short_circuit" time="0.008"><error message="failed on setup with &quot;OSError: could not create numbered dir with prefix test_export_csv_etag_short_cir in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries&quot;">fixturedef = &lt;FixtureDef argname='tmp_path' scope='function' baseid=''&gt;
request = &lt;SubRequest 'tmp_path' for &lt;Function test_export_csv_etag_short_circuit&gt;&gt;

    @pytest.hookimpl(wrapper=True)
    def pytest_fixture_setup(fixturedef: FixtureDef, request) -&gt; object | None:
        asyncio_mode = _get_asyncio_mode(request.config)
        if not _is_asyncio_fixture_function(fixturedef.func):
            if asyncio_mode == Mode.STRICT:
                # Ignore async fixtures without explicit asyncio mark in strict mode
                # This applies to pytest_trio fixtures, for example
                return (yield)
            if not _is_coroutine_or_asyncgen(fixturedef.func):
&gt;               return (yield)
                        ^^^^^
E               OSError: could not create numbered dir with prefix test_export_csv_etag_short_cir in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries

.venv\Lib\site-packages\pytest_asyncio\plugin.py:735: OSError</error></testcase><testcase classname="tests.integration.test_api_ui_export" name="test_export_svg_sector_employment" time="0.008"><error message="failed on setup with &quot;OSError: could not create numbered dir with prefix test_export_svg_sector_employm in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries&quot;">fixturedef = &lt;FixtureDef argname='tmp_path' scope='function' baseid=''&gt;
request = &lt;SubRequest 'tmp_path' for &lt;Function test_export_svg_sector_employment&gt;&gt;

    @pytest.hookimpl(wrapper=True)
    def pytest_fixture_setup(fixturedef: FixtureDef, request) -&gt; object | None:
        asyncio_mode = _get_asyncio_mode(request.config)
        if not _is_asyncio_fixture_function(fixturedef.func):
            if asyncio_mode == Mode.STRICT:
                # Ignore async fixtures without explicit asyncio mark in strict mode
                # This applies to pytest_trio fixtures, for example
                return (yield)
            if not _is_coroutine_or_asyncgen(fixturedef.func):
&gt;               return (yield)
                        ^^^^^
E               OSError: could not create numbered dir with prefix test_export_svg_sector_employm in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries

.venv\Lib\site-packages\pytest_asyncio\plugin.py:735: OSError</error></testcase><testcase classname="tests.integration.test_api_ui_export" name="test_export_svg_etag_short_circuit" time="0.008"><error message="failed on setup with &quot;OSError: could not create numbered dir with prefix test_export_svg_etag_short_cir in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries&quot;">fixturedef = &lt;FixtureDef argname='tmp_path' scope='function' baseid=''&gt;
request = &lt;SubRequest 'tmp_path' for &lt;Function test_export_svg_etag_short_circuit&gt;&gt;

    @pytest.hookimpl(wrapper=True)
    def pytest_fixture_setup(fixturedef: FixtureDef, request) -&gt; object | None:
        asyncio_mode = _get_asyncio_mode(request.config)
        if not _is_asyncio_fixture_function(fixturedef.func):
            if asyncio_mode == Mode.STRICT:
                # Ignore async fixtures without explicit asyncio mark in strict mode
                # This applies to pytest_trio fixtures, for example
                return (yield)
            if not _is_coroutine_or_asyncgen(fixturedef.func):
&gt;               return (yield)
                        ^^^^^
E               OSError: could not create numbered dir with prefix test_export_svg_etag_short_cir in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries

.venv\Lib\site-packages\pytest_asyncio\plugin.py:735: OSError</error></testcase><testcase classname="tests.integration.test_api_ui_export" name="test_export_svg_salary_yoy" time="0.008"><error message="failed on setup with &quot;OSError: could not create numbered dir with prefix test_export_svg_salary_yoy in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries&quot;">fixturedef = &lt;FixtureDef argname='tmp_path' scope='function' baseid=''&gt;
request = &lt;SubRequest 'tmp_path' for &lt;Function test_export_svg_salary_yoy&gt;&gt;

    @pytest.hookimpl(wrapper=True)
    def pytest_fixture_setup(fixturedef: FixtureDef, request) -&gt; object | None:
        asyncio_mode = _get_asyncio_mode(request.config)
        if not _is_asyncio_fixture_function(fixturedef.func):
            if asyncio_mode == Mode.STRICT:
                # Ignore async fixtures without explicit asyncio mark in strict mode
                # This applies to pytest_trio fixtures, for example
                return (yield)
            if not _is_coroutine_or_asyncgen(fixturedef.func):
&gt;               return (yield)
                        ^^^^^
E               OSError: could not create numbered dir with prefix test_export_svg_salary_yoy in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries

.venv\Lib\site-packages\pytest_asyncio\plugin.py:735: OSError</error></testcase><testcase classname="tests.integration.test_api_ui_export" name="test_export_csv_ttl_validation" time="0.008"><error message="failed on setup with &quot;OSError: could not create numbered dir with prefix test_export_csv_ttl_validation in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries&quot;">fixturedef = &lt;FixtureDef argname='tmp_path' scope='function' baseid=''&gt;
request = &lt;SubRequest 'tmp_path' for &lt;Function test_export_csv_ttl_validation&gt;&gt;

    @pytest.hookimpl(wrapper=True)
    def pytest_fixture_setup(fixturedef: FixtureDef, request) -&gt; object | None:
        asyncio_mode = _get_asyncio_mode(request.config)
        if not _is_asyncio_fixture_function(fixturedef.func):
            if asyncio_mode == Mode.STRICT:
                # Ignore async fixtures without explicit asyncio mark in strict mode
                # This applies to pytest_trio fixtures, for example
                return (yield)
            if not _is_coroutine_or_asyncgen(fixturedef.func):
&gt;               return (yield)
                        ^^^^^
E               OSError: could not create numbered dir with prefix test_export_csv_ttl_validation in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries

.venv\Lib\site-packages\pytest_asyncio\plugin.py:735: OSError</error></testcase><testcase classname="tests.integration.test_api_ui_export" name="test_export_svg_deterministic" time="0.008"><error message="failed on setup with &quot;OSError: could not create numbered dir with prefix test_export_svg_deterministic in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries&quot;">fixturedef = &lt;FixtureDef argname='tmp_path' scope='function' baseid=''&gt;
request = &lt;SubRequest 'tmp_path' for &lt;Function test_export_svg_deterministic&gt;&gt;

    @pytest.hookimpl(wrapper=True)
    def pytest_fixture_setup(fixturedef: FixtureDef, request) -&gt; object | None:
        asyncio_mode = _get_asyncio_mode(request.config)
        if not _is_asyncio_fixture_function(fixturedef.func):
            if asyncio_mode == Mode.STRICT:
                # Ignore async fixtures without explicit asyncio mark in strict mode
                # This applies to pytest_trio fixtures, for example
                return (yield)
            if not _is_coroutine_or_asyncgen(fixturedef.func):
&gt;               return (yield)
                        ^^^^^
E               OSError: could not create numbered dir with prefix test_export_svg_deterministic in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries

.venv\Lib\site-packages\pytest_asyncio\plugin.py:735: OSError</error></testcase><testcase classname="tests.integration.test_api_ui_export" name="test_export_png_disabled_by_default" time="0.008"><error message="failed on setup with &quot;OSError: could not create numbered dir with prefix test_export_png_disabled_by_de in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries&quot;">fixturedef = &lt;FixtureDef argname='tmp_path' scope='function' baseid=''&gt;
request = &lt;SubRequest 'tmp_path' for &lt;Function test_export_png_disabled_by_default&gt;&gt;

    @pytest.hookimpl(wrapper=True)
    def pytest_fixture_setup(fixturedef: FixtureDef, request) -&gt; object | None:
        asyncio_mode = _get_asyncio_mode(request.config)
        if not _is_asyncio_fixture_function(fixturedef.func):
            if asyncio_mode == Mode.STRICT:
                # Ignore async fixtures without explicit asyncio mark in strict mode
                # This applies to pytest_trio fixtures, for example
                return (yield)
            if not _is_coroutine_or_asyncgen(fixturedef.func):
&gt;               return (yield)
                        ^^^^^
E               OSError: could not create numbered dir with prefix test_export_png_disabled_by_de in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries

.venv\Lib\site-packages\pytest_asyncio\plugin.py:735: OSError</error></testcase><testcase classname="tests.integration.test_api_ui_export" name="test_export_png_enabled" time="0.008"><error message="failed on setup with &quot;OSError: could not create numbered dir with prefix test_export_png_enabled in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries&quot;">fixturedef = &lt;FixtureDef argname='tmp_path' scope='function' baseid=''&gt;
request = &lt;SubRequest 'tmp_path' for &lt;Function test_export_png_enabled&gt;&gt;

    @pytest.hookimpl(wrapper=True)
    def pytest_fixture_setup(fixturedef: FixtureDef, request) -&gt; object | None:
        asyncio_mode = _get_asyncio_mode(request.config)
        if not _is_asyncio_fixture_function(fixturedef.func):
            if asyncio_mode == Mode.STRICT:
                # Ignore async fixtures without explicit asyncio mark in strict mode
                # This applies to pytest_trio fixtures, for example
                return (yield)
            if not _is_coroutine_or_asyncgen(fixturedef.func):
&gt;               return (yield)
                        ^^^^^
E               OSError: could not create numbered dir with prefix test_export_png_enabled in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries

.venv\Lib\site-packages\pytest_asyncio\plugin.py:735: OSError</error></testcase><testcase classname="tests.integration.test_api_ui_export" name="test_csv_export_invalid_resource" time="0.010"><failure message="OSError: [Errno 28] No space left on device">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_csv_export_invalid_resour0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09EFF070&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_csv_export_invalid_resour0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0AF70210&gt;

    def test_csv_export_invalid_resource(tmp_path: Path, monkeypatch: object) -&gt; None:
        """Test that invalid resource returns validation error."""
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_api_ui_export.py:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_csv_export_invalid_resour0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB09EFF070&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</failure></testcase><testcase classname="tests.integration.test_api_ui_export" name="test_svg_export_invalid_chart" time="0.010"><failure message="OSError: [Errno 28] No space left on device">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_svg_export_invalid_chart0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB0A049C70&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_svg_export_invalid_chart0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0CAAD510&gt;

    def test_svg_export_invalid_chart(tmp_path: Path, monkeypatch: object) -&gt; None:
        """Test that invalid chart type returns validation error."""
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_api_ui_export.py:286: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_svg_export_invalid_chart0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB0A049C70&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</failure></testcase><testcase classname="tests.integration.test_audit_log" name="test_file_audit_log" time="0.008"><error message="failed on setup with &quot;OSError: could not create numbered dir with prefix test_file_audit_log in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries&quot;">fixturedef = &lt;FixtureDef argname='tmp_path' scope='function' baseid=''&gt;
request = &lt;SubRequest 'tmp_path' for &lt;Function test_file_audit_log&gt;&gt;

    @pytest.hookimpl(wrapper=True)
    def pytest_fixture_setup(fixturedef: FixtureDef, request) -&gt; object | None:
        asyncio_mode = _get_asyncio_mode(request.config)
        if not _is_asyncio_fixture_function(fixturedef.func):
            if asyncio_mode == Mode.STRICT:
                # Ignore async fixtures without explicit asyncio mark in strict mode
                # This applies to pytest_trio fixtures, for example
                return (yield)
            if not _is_coroutine_or_asyncgen(fixturedef.func):
&gt;               return (yield)
                        ^^^^^
E               OSError: could not create numbered dir with prefix test_file_audit_log in C:\Users\admin-salim\AppData\Local\Temp\2\pytest-of-admin-salim\pytest-169 after 10 tries

.venv\Lib\site-packages\pytest_asyncio\plugin.py:735: OSError</error></testcase><testcase classname="tests.integration.test_council_end_to_end" name="test_council_run_on_synthetic" time="0.010"><error message="failed on setup with &quot;OSError: [Errno 28] No space left on device&quot;">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_council_run_on_synthetic0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB0A04A680&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_council_run_on_synthetic0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0AE09E90&gt;

    @pytest.fixture
    def synthetic_data_env(tmp_path, monkeypatch):
        """Set up synthetic data environment."""
        # Generate synthetic data
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_council_end_to_end.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_council_run_on_synthetic0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB0A04A680&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</error></testcase><testcase classname="tests.integration.test_council_end_to_end" name="test_council_findings_structure" time="0.010"><error message="failed on setup with &quot;OSError: [Errno 28] No space left on device&quot;">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_council_findings_structur0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB0A091CA0&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_council_findings_structur0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0BCFBE90&gt;

    @pytest.fixture
    def synthetic_data_env(tmp_path, monkeypatch):
        """Set up synthetic data environment."""
        # Generate synthetic data
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_council_end_to_end.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_council_findings_structur0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB0A091CA0&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</error></testcase><testcase classname="tests.integration.test_council_end_to_end" name="test_council_consensus_numeric" time="0.010"><error message="failed on setup with &quot;OSError: [Errno 28] No space left on device&quot;">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_council_consensus_numeric0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB0A0926B0&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_council_consensus_numeric0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0CA62910&gt;

    @pytest.fixture
    def synthetic_data_env(tmp_path, monkeypatch):
        """Set up synthetic data environment."""
        # Generate synthetic data
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_council_end_to_end.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_council_consensus_numeric0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB0A0926B0&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</error></testcase><testcase classname="tests.integration.test_council_end_to_end" name="test_council_verification_format" time="0.010"><error message="failed on setup with &quot;OSError: [Errno 28] No space left on device&quot;">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_council_verification_form0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB0A091CA0&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_council_verification_form0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0C8966D0&gt;

    @pytest.fixture
    def synthetic_data_env(tmp_path, monkeypatch):
        """Set up synthetic data environment."""
        # Generate synthetic data
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_council_end_to_end.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_council_verification_form0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB0A091CA0&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</error></testcase><testcase classname="tests.integration.test_council_end_to_end" name="test_council_deterministic" time="0.010"><error message="failed on setup with &quot;OSError: [Errno 28] No space left on device&quot;">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_council_deterministic0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB0A0930C0&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_council_deterministic0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0BCDB610&gt;

    @pytest.fixture
    def synthetic_data_env(tmp_path, monkeypatch):
        """Set up synthetic data environment."""
        # Generate synthetic data
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_council_end_to_end.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_council_deterministic0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB0A0930C0&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</error></testcase><testcase classname="tests.integration.test_dashboard_static" name="test_static_dashboard_served" time="0.058" /><testcase classname="tests.integration.test_dashboard_static" name="test_dashboard_has_expected_structure" time="0.015" /><testcase classname="tests.integration.test_dashboard_static" name="test_dashboard_has_export_links" time="0.014" /><testcase classname="tests.integration.test_dashboard_static" name="test_dashboard_has_inline_css" time="0.013" /><testcase classname="tests.integration.test_dashboard_static" name="test_dashboard_has_js" time="0.013" /><testcase classname="tests.integration.test_dashboard_static" name="test_static_css_missing" time="0.007" /><testcase classname="tests.integration.test_dashboard_static" name="test_static_js_served" time="0.007" /><testcase classname="tests.integration.test_data_api_on_synthetic.TestEndToEndDataAPI" name="test_data_api_end_to_end" time="0.011"><failure message="OSError: [Errno 28] No space left on device">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_data_api_end_to_end0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB0A091CA0&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

self = &lt;tests.integration.test_data_api_on_synthetic.TestEndToEndDataAPI object at 0x000001DB08F0BE10&gt;
tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_data_api_end_to_end0')
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x000001DB0BD2EB50&gt;

    def test_data_api_end_to_end(self, tmp_path, monkeypatch):
        """Test complete Data API workflow with synthetic data."""
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_data_api_on_synthetic.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_data_api_end_to_end0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB0A091CA0&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</failure></testcase><testcase classname="tests.integration.test_data_api_on_synthetic.TestEndToEndDataAPI" name="test_all_employment_methods" time="0.010"><error message="failed on setup with &quot;OSError: [Errno 28] No space left on device&quot;">path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_all_employment_methods0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB0A093AD0&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
        with path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f, delimiter=";")
            writer.writerow(CompaniesSchema().columns)
            for cid in range(1, n_companies + 1):
                sector = r.choice(SECTORS)
                size_band = _weighted_choice(
                    r,
                    [
                        ("Micro", 0.15),
                        ("Small", 0.35),
                        ("Medium", 0.30),
                        ("Large", 0.15),
                        ("XL", 0.05),
                    ],
                )
                founded = r.randint(FOUNDED_YEAR_MIN, FOUNDED_YEAR_MAX)
&gt;               writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
E               OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:105: OSError

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "d:\lmis_int\src\qnwis\data\synthetic\seed_lmis.py", line 105, in _write_companies
    writer.writerow([cid, f"Company {cid:05d}", sector, size_band, founded])
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

tmp_path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_all_employment_methods0')

    @pytest.fixture
    def synthetic_data_api(tmp_path):
        """Fixture providing DataAPI with synthetic data."""
&gt;       generate_synthetic_lmis(str(tmp_path))

tests\integration\test_data_api_on_synthetic.py:21: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
src\qnwis\data\synthetic\seed_lmis.py:303: in generate_synthetic_lmis
    _write_companies(companies_path, n_companies, r)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = WindowsPath('C:/Users/admin-salim/AppData/Local/Temp/2/pytest-of-admin-salim/pytest-169/test_all_employment_methods0/companies.csv')
n_companies = 800, r = &lt;random.Random object at 0x000001DB0A093AD0&gt;

    def _write_companies(path: Path, n_companies: int, r: random.Random) -&gt; None:
        """Emit companies.csv with deterministic company roster."""
&gt;       with path.open("w", newline="", encoding="utf-8") as f:
E       OSError: [Errno 28] No space left on device

src\qnwis\data\synthetic\seed_lmis.py:89: OSError</error></testcase><testcase classname="pytest" name="internal" time="0.000"><error message="internal error">Traceback (most recent call last):
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\main.py", line 289, in wrap_session
    session.exitstatus = doit(config, session) or 0
                         ^^^^^^^^^^^^^^^^^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\main.py", line 343, in _main
    config.hook.pytest_runtestloop(session=session)
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_hooks.py", line 512, in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_manager.py", line 120, in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_callers.py", line 167, in _multicall
    raise exception
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_callers.py", line 139, in _multicall
    teardown.throw(exception)
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\logging.py", line 801, in pytest_runtestloop
    return (yield)  # Run all the tests.
            ^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_callers.py", line 139, in _multicall
    teardown.throw(exception)
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\terminal.py", line 688, in pytest_runtestloop
    result = yield
             ^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_callers.py", line 139, in _multicall
    teardown.throw(exception)
  File "D:\lmis_int\.venv\Lib\site-packages\pytest_cov\plugin.py", line 345, in pytest_runtestloop
    result = yield
             ^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_callers.py", line 121, in _multicall
    res = hook_impl.function(*args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\main.py", line 367, in pytest_runtestloop
    item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_hooks.py", line 512, in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_manager.py", line 120, in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_callers.py", line 167, in _multicall
    raise exception
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_callers.py", line 139, in _multicall
    teardown.throw(exception)
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\warnings.py", line 90, in pytest_runtest_protocol
    return (yield)
            ^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_callers.py", line 139, in _multicall
    teardown.throw(exception)
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\assertion\__init__.py", line 192, in pytest_runtest_protocol
    return (yield)
            ^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_callers.py", line 139, in _multicall
    teardown.throw(exception)
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\unittest.py", line 475, in pytest_runtest_protocol
    return (yield)
            ^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_callers.py", line 139, in _multicall
    teardown.throw(exception)
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\faulthandler.py", line 88, in pytest_runtest_protocol
    return (yield)
            ^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_callers.py", line 121, in _multicall
    res = hook_impl.function(*args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\runner.py", line 117, in pytest_runtest_protocol
    runtestprotocol(item, nextitem=nextitem)
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\runner.py", line 130, in runtestprotocol
    rep = call_and_report(item, "setup", log)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\runner.py", line 250, in call_and_report
    ihook.pytest_runtest_logreport(report=report)
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_hooks.py", line 512, in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_manager.py", line 120, in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_callers.py", line 167, in _multicall
    raise exception
  File "D:\lmis_int\.venv\Lib\site-packages\pluggy\_callers.py", line 121, in _multicall
    res = hook_impl.function(*args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\terminal.py", line 666, in pytest_runtest_logreport
    self._write_progress_information_filling_space()
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\terminal.py", line 766, in _write_progress_information_filling_space
    self.write(msg.rjust(fill), flush=True, **{color: True})
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\terminal.py", line 509, in write
    self._tw.write(content, flush=flush, **markup)
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\_io\terminalwriter.py", line 177, in write
    self.flush()
  File "D:\lmis_int\.venv\Lib\site-packages\_pytest\_io\terminalwriter.py", line 184, in flush
    self._file.flush()
OSError: [Errno 22] Invalid argument</error></testcase></testsuite></testsuites>