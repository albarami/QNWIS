# LangGraph Multi-Agent System - Quick Start Guide

## ğŸš€ Getting Started

### Run the New Modular Workflow

```bash
# Set environment variable to use new workflow
$env:QNWIS_WORKFLOW_IMPL = "langgraph"  # PowerShell
# OR
export QNWIS_WORKFLOW_IMPL=langgraph    # Bash

# Run basic test (2-node fast path)
python test_langgraph_basic.py

# Run full test (all 10 nodes)
python test_langgraph_full.py
```

### Use from Python Code

```python
from qnwis.orchestration.workflow import run_intelligence_query

# Execute query
result = await run_intelligence_query(
    "What is Qatar's GDP growth from 2010 to 2024?"
)

# Access results
print(f"Complexity: {result['complexity']}")
print(f"Nodes executed: {result['nodes_executed']}")
print(f"Data quality: {result['data_quality_score']:.2f}")
print(f"Confidence: {result['confidence_score']:.2f}")
print(f"\nFinal synthesis:\n{result['final_synthesis']}")
```

### Use via Streaming API

```python
from qnwis.orchestration.streaming import run_workflow_stream

async for event in run_workflow_stream(question="Your query here"):
    print(f"{event.stage}: {event.status}")
    if event.status == "complete":
        print(f"  Latency: {event.latency_ms}ms")
        print(f"  Payload: {event.payload}")
```

---

## ğŸ”§ Configuration

### Feature Flags

Control which workflow implementation to use:

| Environment Variable | Values | Default |
|---------------------|--------|---------|
| `QNWIS_WORKFLOW_IMPL` | `legacy`, `langgraph` | `legacy` |

### LLM Provider

Control which LLM provider nodes use:

| Environment Variable | Values | Default |
|---------------------|--------|---------|
| `QNWIS_LANGGRAPH_LLM_PROVIDER` | `anthropic`, `openai`, `stub` | `stub` |
| `QNWIS_LANGGRAPH_LLM_MODEL` | Model name | Provider default |

### Example Configuration

```bash
# .env file
QNWIS_WORKFLOW_IMPL=langgraph
QNWIS_LANGGRAPH_LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-your-key-here
```

---

## ğŸ“Š Understanding the Workflow

### Query Flow

```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Classifier    â”‚ â† Analyzes complexity (simple/medium/complex/critical)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Extraction    â”‚ â† Fetches data (cache-first <100ms + 12 APIs)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
    â”‚          â”‚
Simple    Medium/Complex
    â”‚          â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚    â”‚ Financial â”‚ â† Financial economist analysis
    â”‚    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚          â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚    â”‚  Market   â”‚ â† Market intelligence + GCC benchmarking
    â”‚    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚          â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚    â”‚Operations â”‚ â† Implementation feasibility
    â”‚    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚          â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚    â”‚ Research  â”‚ â† Semantic Scholar + academic evidence
    â”‚    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚          â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚    â”‚  Debate   â”‚ â† Contradiction resolution
    â”‚    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚          â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚    â”‚ Critique  â”‚ â† Devil's advocate
    â”‚    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚          â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚    â”‚Verificationâ”‚ â† Fact checking + citations
    â”‚    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚          â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚Synthesisâ”‚ â† Final ministerial brief
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
        END
```

### Performance by Complexity

| Complexity | Nodes | Time | Use Case |
|-----------|-------|------|----------|
| **Simple** | 3 | 2-5s | "What is unemployment rate?" |
| **Medium** | 10 | 20-40s | "Analyze employment trends" |
| **Complex** | 10 | 30-60s | "Should Qatar invest $15B in..." |

---

## ğŸ§ª Testing

### Run All Tests

```bash
# Basic workflow (fast)
python test_langgraph_basic.py

# Full workflow (comprehensive)
python test_langgraph_full.py

# Verify cache performance
python verify_cache.py
```

### Expected Output

**Basic Test (Simple Query):**
```
Complexity: simple
Nodes executed: ['classifier', 'extraction', 'synthesis']
Facts extracted: 20+
Data quality: 0.70+
Execution time: <30s
```

**Full Test (Complex Query):**
```
Complexity: medium
Nodes executed: ['classifier', 'extraction', 'financial', 'market',
                 'operations', 'research', 'debate', 'critique',
                 'verification', 'synthesis']
Facts extracted: 145+
Data quality: 0.96+
Confidence score: 0.40-0.80
```

---

## ğŸ” Debugging

### Enable Debug Logging

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Check Which Workflow Is Active

```python
from qnwis.orchestration.feature_flags import get_workflow_implementation

print(f"Active workflow: {get_workflow_implementation()}")
# Output: "legacy" or "langgraph"
```

### Inspect State at Each Node

```python
from qnwis.orchestration.workflow import run_intelligence_query

result = await run_intelligence_query("Your query")

# Check reasoning chain
for step in result["reasoning_chain"]:
    print(f"  - {step}")

# Check nodes executed
print(f"Nodes: {result['nodes_executed']}")

# Check warnings/errors
if result["warnings"]:
    print(f"Warnings: {result['warnings']}")
if result["errors"]:
    print(f"Errors: {result['errors']}")
```

---

## ğŸ“ File Structure

```
src/qnwis/orchestration/
â”œâ”€â”€ state.py                   # State schema (IntelligenceState)
â”œâ”€â”€ workflow.py                # Main workflow (10-node graph)
â”œâ”€â”€ feature_flags.py           # Migration feature flags
â”œâ”€â”€ streaming.py               # Streaming adapter (legacy compat)
â”œâ”€â”€ nodes/                     # Modular nodes
â”‚   â”œâ”€â”€ __init__.py           # Node exports
â”‚   â”œâ”€â”€ README.md             # Architecture docs
â”‚   â”œâ”€â”€ _helpers.py           # Shared utilities
â”‚   â”œâ”€â”€ classifier.py         # Node 1: Complexity routing
â”‚   â”œâ”€â”€ extraction.py         # Node 2: Data prefetch
â”‚   â”œâ”€â”€ financial.py          # Node 3: Financial analysis
â”‚   â”œâ”€â”€ market.py             # Node 4: Market intelligence
â”‚   â”œâ”€â”€ operations.py         # Node 5: Operations feasibility
â”‚   â”œâ”€â”€ research.py           # Node 6: Research evidence
â”‚   â”œâ”€â”€ debate.py             # Node 7: Contradiction resolution
â”‚   â”œâ”€â”€ critique.py           # Node 8: Devil's advocate
â”‚   â”œâ”€â”€ verification.py       # Node 9: Fact checking
â”‚   â””â”€â”€ synthesis.py          # Node 10: Final synthesis
â”œâ”€â”€ prefetch_apis.py           # Data prefetch (reused)
â”œâ”€â”€ legendary_debate_orchestrator.py  # 6-phase debates (available)
â””â”€â”€ graph_llm.py              # Legacy workflow (deprecated)
```

---

## ğŸ¯ Common Use Cases

### Query Classification

```python
# Simple fact lookup
"What is Qatar's current unemployment rate?"
â†’ Nodes: classifier â†’ extraction â†’ synthesis
â†’ Time: 2-5s

# Medium analysis
"Analyze Qatar's employment trends over the last 5 years"
â†’ Nodes: All 10
â†’ Time: 20-40s

# Complex strategic decision
"Should Qatar invest QAR 15B in green hydrogen by 2030?"
â†’ Nodes: All 10 + extended debate
â†’ Time: 30-60s
```

### Data Source Integration

The extraction node automatically uses:
- **PostgreSQL cache**: 128 World Bank + 1 ILO indicators (<100ms)
- **IMF API**: Economic dashboard (free tier)
- **World Bank API**: 1400+ development indicators
- **GCC-STAT**: Regional labor statistics
- **Perplexity AI**: Real-time synthesis
- **Semantic Scholar**: 200M+ academic papers
- **Brave Search**: Recent news articles

### Error Recovery

The workflow gracefully handles:
- LLM timeout errors â†’ Logs warning, continues
- Missing data â†’ Records gap, continues
- API failures â†’ Uses cached data, continues
- Agent failures â†’ Stores error, continues

---

## ğŸ“š Additional Resources

- **Node Architecture**: `src/qnwis/orchestration/nodes/README.md`
- **State Schema**: `src/qnwis/orchestration/state.py`
- **Feature Flags**: `src/qnwis/orchestration/feature_flags.py`
- **Migration Plan**: `LANGGRAPH_REFACTOR_COMPLETE.md`
- **Original Article**: `ARTICLE_QNWIS_SYSTEM.md`

---

## ğŸ†˜ Troubleshooting

### Issue: "No module named 'langgraph'"
**Solution:**
```bash
pip install langgraph>=0.0.20
```

### Issue: "ANTHROPIC_API_KEY is required"
**Solution:**
```bash
# Use stub provider for testing
$env:QNWIS_LANGGRAPH_LLM_PROVIDER = "stub"
```

### Issue: "legacy workflow still running"
**Solution:**
```bash
# Explicitly enable new workflow
$env:QNWIS_WORKFLOW_IMPL = "langgraph"
```

### Issue: Tests run but show old behavior
**Solution:**
```bash
# Clear Python cache
Remove-Item -Recurse -Force src/qnwis/orchestration/__pycache__
Remove-Item -Recurse -Force src/qnwis/orchestration/nodes/__pycache__

# Re-run test
python test_langgraph_full.py
```

---

**Last Updated:** November 22, 2025  
**Version:** 1.0.0 (Modular LangGraph Architecture)

